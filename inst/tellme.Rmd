---
title: "Tellme Benchmark Report for LPJ-GUESS"
author: "Matthew Forrest (current lead and contact person)"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
output: 
 html_document:
  toc: true
params:
  new_directory:
    value: "/home/mforrest/GuessRuns/Tellus_dev/output11690tls-3"
  new_name:
    value: "New Run"
  old_directory:
    value: "/home/mforrest/GuessRuns/Tellus_dev/trunk10115crg+monthly"
  old_name:
    value: "Old Run"
  data_directory: 
    value: "/data/shared/Tellus"
  land_cover_file:
    value: "/data/mforrest/LandUseLandCover/LUH2_GCP2019/lu_1549_2019_luh2_aggregate_sum2x2_midpoint_nourban_gcp2019_2019_10_22.txt"
---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      out.width = '100%',
                      fig.height = 7)
# kable options
opts <- options(knitr.kable.NA = "")


library(ggplot2)
# set the ggplot theme to avoid the grey background that Stefan hates so much
theme_set(theme_bw())

library(DGVMTools)
library(DGVMBenchmarks)
library(terra)
library(viridis)
library(mapproj)
library(pals)
library(knitr)
library(dplyr)
library(kableExtra)

library(tictoc)

# conversion factors
KG_TO_PG <- 1/1e+12
KG_TO_TG <- 1/1e+9
M2_TO_MegaM2 <- 1/1e+12
M2_TO_Mha <- 1/1e+10
L_TO_KM3 <- 1/1e+12

# lons and lats for calculating area totals from sparsely populated grids
hd_lons <- seq(-179.75, 179.75, by = 0.5)
hd_lats <- seq(-89.75, 89.75, by = 0.5)

# start timer
tic()


```

# Settings {.tabset}

## Click here to hide settings

## Click here to show settings

```{r settings, echo = TRUE}

#### DEFINE LPJ-GUESS RUNS ####
# NOTE:
#  The paths defined in the "dir" argument only point to the overall benchmark directory.  
#  To actually access one of the benchmark runs (ie "tellus" or "crop_global") you should copy these Source objects 
#  and manually append the benchmark directory name to the "dir".  See the GCP code block for an example.

# new
new_simulation_Source <- defineSource(name = params$new_name,
                                      dir = params$new_directory,
                                      format = GUESS)


# reference run
old_simulation_Source <- defineSource(name = params$old_name,
                                      dir = params$old_directory,
                                      format = GUESS)

# combine into a list for looping later
all_simulation_Sources_list <- list(old_simulation_Source, new_simulation_Source)

# quick read switch and version label (for making quick read files)
quick_read <- TRUE
analysis_version <- "tellus_v1.2" 

# do verbose reads - this makes a lot of printed output which will appear in the report, only enable for developing/debugging the reading code
verbose_read <- FALSE

# do publication plots
doPublicationPlots <- FALSE

# plot maps (turn off to save time)
doMapPlots <- FALSE

# switches for which benchmarks to do
do_Global_Summary_Tables <- FALSE
do_GCP_NBP <- TRUE
do_Biomes <- FALSE
do_global_GPP <- TRUE
do_global_LAI <- TRUE
do_global_BA <- TRUE
do_Global_Biomass <- TRUE
do_Pan_Biomass <- FALSE
do_Regrowth <- FALSE

# Summary periods
summary_periods <- list(c(1961, 1990),
                        c(1990, 2000))


#  **** SPECIAL SUBSETTING FOR STEFAN'S GLOBAL RETUNING  ****
subset_1600_gridcells <- read.table(system.file("extdata", "Gridlist", "gridlist_16_random.csv", package = "DGVMBenchmarks"), header = TRUE, flush = TRUE)
#  **** END SPECIAL SUBSETTING ****

# Spatial extent - note that this only applies to some benchmarks - typically the spatially explicit global ones
# it will be ignored for benchmarks such as the regrowth and Pan forest biomass benchmarks

# spatial extent (can be a raster:: extent of a a two cloum data.frame of gridcells), set to NULL for no subsetting
spatial_extent <- subset_1600_gridcells 
# spatial_extent <- extent(c(xmin = -10, ymin = 35, xmax = 35, ymax  = 72)) 
#spatial_extent <-  NULL 

# set to a string to describe the spatial subset and use "Global" if not cropping area
spatial_extent_id <- "The1600"
# spatial_extent_id <- "Europe" 
#spatial_extent_id <- "Global" 




# Standard plot formatting arguments
num_cols <- 1
map_overlay <- "coastlines"
stats_lon <- -130
stats_lat <- -20


```



``` {r silent preamble and preparation}


# version label for labelling saved data
version_label <- paste(analysis_version, spatial_extent_id, sep = "_")

# Prepare the (empty) summary table of global numbers
# make the columns names and types
summary_col_names <- c("Quantity", "Unit")
for(this_sim in all_simulation_Sources_list) {
  summary_col_names <- append(summary_col_names, this_sim@name)
}
summary_col_names <- append(summary_col_names, c("Data", "Dataset", "Dataset ref."))
summary_table <- data.frame(check.names = FALSE, stringsAsFactors = FALSE)

# this table is completely empty, it will by built benchmark by-benchmark
metric_table <- data.frame(check.names = FALSE, stringsAsFactors = FALSE)


```


***


# Global Carbon Project Net Biome Poductivity

Potential intro text about GCP, links to online description of the data, what to look for in the benchmark, etc.


```{r gcp, fig.height=5}

if(do_GCP_NBP){
  
  
  ### Read the data and calculate the annual mean over the whole period
  GCP_full_Field <- read_GCP()
  GCP_full_Field_ymean  <- suppressWarnings(aggregateYears(GCP_full_Field, "mean"))
  
  
  this_benchmark <- new("Benchmark",
                        id = "GCP_NBP",
                        name = "GCP NBP",
                        description = "Global NBP",
                        simulation = "tellus",
                        guess_var = "cflux",
                        guess_layers = "NBP",
                        unit = "kg m^-2^ y^-1^",
                        agg.unit = "PgC y^-1^",
                        datasets = list(GCP_full_Field),
                        first.year = 1959,
                        last.year = 2015,
                        metrics = c("r2"))
  
  
  # make a list of all Fields to be compared  (this will also include whatever model runs are available)
  all_NBP_Fields_list <- list()
  all_NBP_global_sums <- list()
  all_NBP_Fields_list[[GCP_full_Field@source@name]] <- GCP_full_Field
  # and the vector of labels to eventual put on the plot
  all_NBP_labels_vector <- c(paste0("GCB residual: ", signif(GCP_full_Field_ymean@data[["NBP"]], 3), " PgC/year"))
  
  
  # make the line for the global summary table
  summary_NBP_line <- makeSummaryLine(this_benchmark, summary_col_names)
  summary_NBP_line$Data <- signif(GCP_full_Field_ymean@data[["NBP"]], 3)
  
  
  ### Read the LPJ-GUESS data
  
  
  # loop through model runs to be processed and store the full data 
  all_sim_full_NBP <- list()
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    this_benchmark_run_dir <- file.path(this_sim_Source@dir, this_benchmark@simulation)
    if(file.exists(file.path(this_benchmark_run_dir, "cflux.out")) || file.exists(file.path(this_benchmark_run_dir, "cflux.out.gz"))) {
      
      # make local sources pointing to the simulation subrun directory
      this_subrun_Source <- this_sim_Source
      this_subrun_Source@dir <- this_benchmark_run_dir
      
      # read the data and process it into global sums
      this_simulation_NBP <- getField(source = this_subrun_Source,
                                      this_benchmark@guess_var,
                                      first.year = this_benchmark@first.year,
                                      last.year = this_benchmark@last.year,
                                      verbose = verbose_read,
                                      quick.read = quick_read,
                                      quick.read.file = paste("cflux", version_label, sep = "_") 
      )
      
      if("NEE" %in% names(this_simulation_NBP)) renameLayers(this_simulation_NBP, "NEE", "NBP")
      
      # save for possibly using later
      all_sim_full_NBP[[this_sim_Source@name]] <- this_simulation_NBP
      
      # aggregate with weighted sum and adjust units
      this_simulation_NBP_agg <- aggregateSpatial(this_simulation_NBP, method = "w.sum", lon_centres = hd_lons, lat_centres = hd_lats)
      this_simulation_NBP_agg <- layerOp(x = this_simulation_NBP_agg, operator = "mulc", layers = layers(this_simulation_NBP_agg), new.layer = layers(this_simulation_NBP_agg), constant = -KG_TO_PG)
      
      # store the Field in the list of all Fields for plotting later
      all_NBP_Fields_list[[this_sim_Source@name]] <- this_simulation_NBP_agg
      
      # calculate yearly means of whole period
      # supressWarnings is just to stops warnings that there is no spatial or temporal data in the resulting Field
      # (all averaged away to give a single number)
      this_simulation_NBP_ymean <- suppressWarnings(aggregateYears(this_simulation_NBP_agg, "mean"))
      
      # make a text label for putting the yearly mean on th plot and aa it to the label vector of labels
      all_NBP_labels_vector <- append(all_NBP_labels_vector, paste0(this_simulation_NBP_ymean@source@name, 
                                                                    ": ", 
                                                                    signif(this_simulation_NBP_ymean@data[["NBP"]],3), 
                                                                    " PgC/year"))
      
      # save this to the summary table, but it *may* be over-written later is spatial subsetting was selected
      summary_NBP_line[[this_sim_Source@name]] <- signif(this_simulation_NBP_ymean@data[["NBP"]], 3) 
    } 
    
  }
  
  
  # plot all together
  NBP_plot <- plotTemporal(all_NBP_Fields_list, 
                           col.by = "Source", 
                           layers = "NBP", 
                           title = "Global NBP", 
                           subtitle = NULL, 
                           y.label = "Global NBP (PgC/year)",
                           text.multiplier = 1.5, 
                           sizes = 1)
  
  # make a simple data.frame to put numbers on the plot, and then add it to the plot
  global.numbers.df <- data.frame(x= rep(as.Date(paste(this_benchmark@first.year), "%Y")), 
                                  y = c(6, 5, 4), 
                                  label = all_NBP_labels_vector)
  NBP_plot <-  NBP_plot + geom_text(data = global.numbers.df,  mapping = aes(x = x, y = y, label = label), size = 6, hjust = 0, col = "black")
  print(NBP_plot)
  
  # calculate R^2 on this data
  all_NBP_temporal_comparisons <- fullTemporalComparison(benchmark = this_benchmark, 
                                                         all_ts = all_NBP_Fields_list, 
                                                         new_model = params$new_name,
                                                         old_model = params$old_name) 
  
  metric_table <- rbind(metric_table, 
                        makeMetricTable(benchmark = this_benchmark, 
                                        all_comparisons_list = all_NBP_temporal_comparisons, 
                                        all_simulations_Sources_list = all_simulation_Sources_list))
  
  # Calculate area sum based on subset, if the spatial_extent is not NULL
  if(!is.null(spatial_extent)) {
    
    for(this_sim_Source in all_simulation_Sources_list) {
      
      # subset and aggregrage the already read data
      # if the provided spatial yields a valid extent, use the crop function
      possible.error <- try (extent(spatial_extent), silent=TRUE )
      # note that data.tables *do* return a valid extent, but we don't want to crop with that here (hence the second condition)
      if (!inherits(possible.error, "try-error") && !is.data.table(spatial.extent)) {
        this_simulation_NBP_subset <- crop(x =  all_sim_full_NBP[[this_sim_Source@name]], y = spatial_extent, spatial.extent.id = spatial_extent_id)  
      }
      # else check if some gridcells to be selected with getGridcells
      else if(is.data.frame(spatial_extent) || is.data.table(spatial_extent) || is.numeric(spatial_extent) || class(spatial_extent)[1] == "SpatialPolygonsDataFrame"){
        this_simulation_NBP_subset <- selectGridcells(x = all_sim_full_NBP[[this_sim_Source@name]], gridcells = spatial_extent, spatial.extent.id = spatial_extent_id)
      }
      
      # aggregate with weighted sum and adjust units
      this_simulation_NBP_agg <- aggregateSpatial(this_simulation_NBP_subset, method = "w.sum", lon_centres = hd_lons, lat_centres = hd_lats)
      this_simulation_NBP_agg <- layerOp(x = this_simulation_NBP_agg, operator = "mulc", layers = layers(this_simulation_NBP_agg), new.layer = layers(this_simulation_NBP_agg), constant = -KG_TO_PG)
      summary_NBP_line[[this_sim_Source@name]] <- signif(suppressWarnings(aggregateYears(this_simulation_NBP_agg,"mean"))@data[["NBP"]], 3)
      
    } # for each simulation
    
  } # if spatial extent is not NULL
  
  
  # save the summary line to the table
  summary_table <- rbind(summary_table, summary_NBP_line)
  names(summary_table) <- summary_col_names
}

```

<a href="#top">Back to top</a>

***

# PNV Biomes

##  Dinerstein 2017 ecoregions (no model output classification available)

Any volunteers for performing such a classification?  If you do, Stefan will buy you a beer.

## Haxeltine and Prentice 1992 biomes, classification following Smith et al 2014.


```{r Global PNV biomes, fig.height = 9}

#### H&P Biomes ####

if(do_Biomes){
  
  # Define the benchmark
  this_benchmark <- list(
    description = "Global biomes",
    simulation = c("global", "tellus"),
    guess_var = "lai"
  )
  
  ### the benchmarking datasets for global biomass
  smith_biomes = list(
    first_year = 1960,
    last_year = 1990,
    dir = "biomes/HanP_PNV",
    file_name = "Smith2014.nc",
    id = "Smith2014",
    name = "Haxeltine and Prentice 1992 biomes",
    this_unit = "PgC"
  )
  this_dataset <- smith_biomes
  
  ### Lists for storing the field and totals
  ###  NOTE: This gets a special name cause it is used later
  Biome_Map_Fields_list <- list()
  
  #### READ DATASET ####
  full_file_path <- file.path(params$data_directory, this_dataset$dir, this_dataset$file_name)
  if(file.exists(full_file_path)) {
    
    this_source <- defineSource(id = this_dataset$id,
                                name = this_dataset$name,
                                dir = file.path(params$data_directory, this_dataset$dir),
                                format = NetCDF)
    
    suppressWarnings(
      Biome_Map_Fields_list[[this_dataset$name]] <- getField(source = this_source,
                                                             quant = this_dataset$id,
                                                             spatial.extent = spatial_extent,
                                                             spatial.extent.id = spatial_extent_id,  
                                                             first.year = this_dataset$first_year,
                                                             last.year = this_dataset$last_year,
                                                             year.aggregate.method = "mean",
                                                             verbose = verbose_read,
                                                             quick.read = FALSE,
                                                             quick.read.file = paste(this_benchmark$guess_var, version_label, sep = "_")))
    
  }
  else {
    message("Biomes dataset not found, benchmark will be skipped.")
    do_Global_biomass <- FALSE
  }
  
  #### DERIVE BIOMES FROM LPJ-GUESS DATA ####
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    got_simulation <- FALSE
    for(this_simulation in this_benchmark$simulation) {
      this_benchmark_run_dir <- file.path(this_sim_Source@dir, this_simulation)
      if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark$guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark$guess_var, ".out.gz")))) {
        got_simulation <- TRUE
        break
      }
    }
    if(got_simulation){
      
      # read the full data and
      temp_simulation_Source <- this_sim_Source
      temp_simulation_Source@dir <- this_benchmark_run_dir
      suppressWarnings(
        Biome_Map_Fields_list[[this_sim_Source@id]] <- getScheme(source = temp_simulation_Source,
                                                                 scheme = Smith2014BiomeScheme,
                                                                 spatial.extent = spatial_extent,
                                                                 spatial.extent.id = spatial_extent_id,  
                                                                 first.year = this_dataset$first_year,
                                                                 last.year = this_dataset$last_year,
                                                                 year.aggregate.method = "mean",
                                                                 quick.read = quick_read,
                                                                 quick.read.file = paste(this_benchmark$guess_var,version_label, sep = "_"))
      )
      
    } # if file is present 
    else {
      message("Modelled biomass file not found, benchmark will be skipped.")
      do_Global_biomass <- FALSE
    }
    
  } # for each model run
  
  
  if(doMapPlots) {
    suppressWarnings(biome_plot <- plotSpatial(Biome_Map_Fields_list, 
                                               ncol = num_cols, 
                                               text.multiplier = 1.3, 
                                               map.overlay = map_overlay, 
                                               title = NULL))
    biome_plot <- biome_plot + theme(legend.position = "bottom",
                                     legend.text=element_text(size=rel(0.9)),
                                     legend.key.size = unit(0.5, "lines"))
    
    biome_plot <- biome_plot+ guides(fill = guide_legend(ncol = 2))
    suppressWarnings(plot(biome_plot))
  }
  
  
  
} # if do_Global_Biomes
```


<a href="#top">Back to top</a>

***

# GOSIF Gross Primary Productivity

Intro, data links, etc.

```{r GOSIF GPP data prep, echo=FALSE, out.width = '100%'}

if(do_global_GPP){
  
  # Currently only got one GPP dataset, but code as a list of data source for future flexibility
  GPP_data_Fields <- list()
  
  #### GOSIF GPP SETTINGS AND DATA ####
  
  GOSIF_GPP_monthly_dir <- "monthly_gpp/GOSIFGPP"
  GOSIF_GPP_monthly_file.name <- "GOSIF_GPP.txt"
  GOSIF_GPP_Source <- defineSource(id = "GOSIF_GPP",
                                   name = "GOSIF GPP",
                                   dir = file.path(params$data_directory, GOSIF_GPP_monthly_dir),
                                   format = GUESS)
  
  full_file_path <- file.path(GOSIF_GPP_Source@dir, GOSIF_GPP_monthly_file.name)
  if(!file.exists(full_file_path)) {
    print("GOSIF GPP data not available.")
  } else {
    GPP_data_Fields[[GOSIF_GPP_Source@name]] <- getField(source = GOSIF_GPP_Source,
                                                         quant = "mgpp",
                                                         spatial.extent = spatial_extent,
                                                         spatial.extent.id = spatial_extent_id,
                                                         file.name = GOSIF_GPP_monthly_file.name,
                                                         verbose = verbose_read)
  }
  
  
  #### PREPARE GPP BENCHMARK SETTINGS AND DATA ####
  
  if(length(GPP_data_Fields) == 0) {
    do_global_GPP <- FALSE
    print("Skipping GPP benchmark because no datasets available.")
  }
  else {
    
    # find overlapping years (general case if multiple datasets)
    first.year = last.year = NA
    for(this_Field in GPP_data_Fields) {
      first.year <- min(c(this_Field@first.year, first.year), na.rm = TRUE)
      last.year <- max(c(this_Field@last.year, last.year), na.rm = TRUE)
    }
    
    this_benchmark <- new("Benchmark",
                          id = "Global_GPP",
                          name = "Global GPP",
                          description = "Global GPP",
                          simulation = "tellus",
                          guess_var = "mgpp",
                          guess_layers = "mgpp",
                          unit = "kg m^-2^ y^-1^",
                          agg.unit = "PgC y^-1^",
                          datasets = GPP_data_Fields,
                          first.year = first.year,
                          last.year = last.year,
                          metrics = c("NME", "RMSE"))
    
    
    summary_table_lines <- makeSummaryLine(this_benchmark, summary_col_names)
    
    
    ### Lists for storing the appropriate Fields and summary numbers
    all_GPP_Maps <- list()
    all_GPP_Trends <- list()
    all_GPP_Seasonal <- list()
    all_GPP_totals <- list()
    
    # Process the datasets according to the benchmark parameters above
    # this code will likely need to be adjusted depending on the details of variables, units, datasets etc
    for(this_data_Field in this_benchmark@datasets) {
      
      # crop the data to the comment benchmark year
      this_data_Field <- selectYears(this_data_Field, first = this_benchmark@first.year, last = this_benchmark@last.year)
      
      # delete values with -9999 and covert to kg
      this_data_Field@data <- this_data_Field@data[mgpp != -9999.0,]
      
      # Calculate the slope (still in grams)
      all_GPP_Trends[[this_data_Field@source@name]] <- calcLinearTrend(this_data_Field)
      
      # go from g to kg for spatial maps
      this_data_Field <- layerOp(this_data_Field, operator = "divc", constant = 1000, layers = "mgpp", new.layer = "mgpp")
      
      # make the annual map for comparison (leave only spatial)
      all_GPP_Maps[[this_data_Field@source@name]] <- aggregateYears(aggregateSubannual(this_data_Field, method = "sum", target = "Year"), method = "mean")
      
      # make the seasonal cycle for comparison (leave months andspatial)
      all_GPP_Seasonal[[this_data_Field@source@name]] <- aggregateYears(this_data_Field, method = "mean")
      
      # make and save the mean annual global GPP
      # TODO, make this more flexible for multiple datasets
      data_GPP_PgC <- areaWeightedTotal(all_GPP_Maps[[this_data_Field@source@name]], lon_centres = hd_lons, lat_centres = hd_lats)@data*KG_TO_PG
      all_GPP_totals[[this_data_Field@source@name]] <- data_GPP_PgC
      summary_table_lines$Data <- signif(as.numeric(data_GPP_PgC),4)
      
    }
    
    #### READ LPJ-GUESS DATA ####
    
    # loop through model runs to be processed
    for(this_sim_Source in all_simulation_Sources_list) {
      
      # check if file is present (if not don't include this run)
      this_benchmark_run_dir <- file.path(this_sim_Source@dir,this_benchmark@simulation)
      if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark@guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark@guess_var, ".out.gz")))) {
        
        # make local sources pointing to the simulation subrun directory
        this_subrun_Source <- this_sim_Source
        this_subrun_Source@dir <- this_benchmark_run_dir
        
        # read the full data and
        suppressWarnings(
          this_simulation_GPP <- getField(source = this_subrun_Source,
                                          this_benchmark@guess_var,
                                          spatial.extent = spatial_extent,
                                          spatial.extent.id = spatial_extent_id,
                                          first.year = this_benchmark@first.year,
                                          last.year = this_benchmark@last.year,
                                          verbose = verbose_read,
                                          quick.read = quick_read,
                                          quick.read.file = paste(this_benchmark@guess_var, version_label, sep = "_"))
        )
        
        ### take sum of month and average of years and store for later use - very easy ###
        all_GPP_Maps[[this_sim_Source@name]] <- aggregateYears(aggregateSubannual(this_simulation_GPP, target = "Year", method = "sum"),  "mean")
        
        ### take yearly average and store for later use - very easy ###
        all_GPP_Seasonal[[this_sim_Source@name]] <- aggregateYears(this_simulation_GPP, "mean")
        
        ### calculate and store the linear trend and p-value for every gridcell (also change unit to gC/m^-2/month^-2)
        this_GPP_Trend <- calcLinearTrend(this_simulation_GPP)
        this_GPP_Trend <- layerOp( this_GPP_Trend, operator = "mulc", constant = 1000, layers = "Trend", new.layer = "Trend")
        this_GPP_Trend <- layerOp( this_GPP_Trend, operator = "mulc", constant = 1000, layers = "Significant_Trend", new.layer = "Significant_Trend")
        all_GPP_Trends[[this_sim_Source@name]] <- this_GPP_Trend
        
        # calculate and save the global total
        this_GPP_PgC <- areaWeightedTotal(all_GPP_Maps[[this_sim_Source@name]], lon_centres = hd_lons, lat_centres = hd_lats)@data*KG_TO_PG
        all_GPP_totals[[this_sim_Source@name]] <- this_GPP_PgC
        summary_table_lines[[this_sim_Source@name]] <- signif(as.numeric(this_GPP_PgC),4)
        
        # remove to save memory
        rm(this_simulation_GPP)
        
      } # if file is present 
      else {
        do_global_GPP <- FALSE
      }
      
    } # for each model run
    
    
    # do all spatial comparisons and store them in a big list'o'lists to be plotted in the next code chunks
    all_GPP_comparisons <- fullSpatialComparison(this_benchmark, all_GPP_Maps, all_GPP_Trends, all_GPP_Seasonal, params$new_name, params$old_name)
    
    # save the summary table line 
    summary_table <- rbind(summary_table, summary_table_lines)
    
    # make mini metric table for this benchamrk and append to overall table
    metric_table <- rbind(metric_table, 
                          makeMetricTable(benchmark = this_benchmark, 
                                          all_comparisons_list = all_GPP_comparisons, 
                                          all_simulations_Sources_list = all_simulation_Sources_list))
    
  } # if data are available
  
} # if do_global_GPP
```

## Spatial patterns {.tabset}

### Absolute values
```{r}
if(do_global_GPP & doMapPlots){  
  
  # plot all absolute values together
  GPP_abs_values_plot <- plotSpatial(all_GPP_Maps, 
                                     ncol = num_cols, 
                                     legend.title = expression(kgC~m^{"-2"}~year^{"-1"}),
                                     map.overlay = map_overlay, 
                                     title = "Absolute GPP values",
                                     subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # add the total GPP to the plots
  total_label_df <- data.frame()
  for(this_panel in names(all_GPP_totals))  total_label_df <- rbind(total_label_df,
                                                                    list(label = paste(round(all_GPP_totals[[this_panel]], 1), "PgC/year"), 
                                                                         Facet = this_panel, 
                                                                         x = stats_lon, y = stats_lat),
                                                                    stringsAsFactors = FALSE)
  total_label_df$Facet <- factor(total_label_df$Facet, levels = names(all_GPP_totals))
  GPP_abs_values_plot  <- GPP_abs_values_plot  + geom_text(data = total_label_df,  mapping = aes(x = x, y = y, label = label), size = 2.5)
  suppressWarnings(print(GPP_abs_values_plot))
  
}
```

### Differences

```{r}
if(do_global_GPP & doMapPlots){  
  
  GPP_diff_values_plot <- plotSpatialComparison(all_GPP_comparisons[["Values"]], 
                                                ncol = num_cols, 
                                                legend.title = expression(Delta~kgC~m^{"-2"}~year^{"-1"}),
                                                map.overlay = map_overlay, 
                                                title = "GPP biases", 
                                                facet.order = names(all_GPP_comparisons[["Values"]]),
                                                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # extract metric scores and add to the panels
  lat_offset = 0
  for(this_metric in this_benchmark@metrics) {
    metric_label_df <- data.frame()
    for(comparison_name  in names(all_GPP_comparisons[["Values"]])) {
      metric_label_df <- rbind(metric_label_df,
                               list(label = paste(this_metric, "=", round(all_GPP_comparisons[["Values"]][[comparison_name]]@stats[[this_metric]], 2)), 
                                    Facet = comparison_name, 
                                    x = stats_lon, y = stats_lat - lat_offset),
                               stringsAsFactors = FALSE)  
    }
    metric_label_df$Facet <- factor(metric_label_df$Facet, levels = names(all_GPP_comparisons[["Values"]]))
    GPP_diff_values_plot  <- GPP_diff_values_plot  + geom_text(data = metric_label_df,  mapping = aes(x = x, y = y, label = label), size = 3)
    lat_offset <- lat_offset + 10  
  }
  
  suppressWarnings(print(GPP_diff_values_plot))
  
  
}
```



## Temporal trends {.tabset}

### Trend value
```{r}
if(do_global_GPP & doMapPlots) {
  
  suppressWarnings( print(
    plotSpatial(all_GPP_Trends, 
                layers = "Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.2,0.2),
                drop.cuts = FALSE,
                title = "Trend in GPP", 
                legend.title = expression(gC~m^{"-2"}~month^{"-2"}),
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
  
}
```

### Trend significance
```{r}
if(do_global_GPP & doMapPlots) {
  suppressWarnings(print(
    plotSpatial(all_GPP_Trends, 
                layers = "p.value", 
                ncol = num_cols, 
                cols = viridis::turbo(6), 
                cuts = c(0, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0),
                drop.cuts = FALSE,
                title = "Significance in GPP Trends",
                legend.title =  "p value",
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}

```

### Trend Differences
```{r}
if(do_global_GPP & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Trend"]], 
                          ncol = num_cols, 
                          drop.cuts = NULL,
                          title = "Difference Trend in GPP", 
                          legend.title =  expression(Delta~gC~m^{"-2"}~month^{"-2"}),
                          map.overlay = map_overlay,                
                          subtitle =paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Significant Trends
```{r}
if(do_global_GPP & doMapPlots) {
  suppressWarnings( print(
    plotSpatial(all_GPP_Trends, 
                layers = "Significant_Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.2,0.2),
                drop.cuts = FALSE,
                title = "Significant Trend in GPP (p-value < 0.05)", 
                legend.title = expression(gC~m^{"-2"}~month^{"-2"}),
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```



## Seasonal analysis {.tabset}
Definition of seasonal concentration and phase follow Kelley *et al.* 2013.  **Seasonal concentration** equals one if the variable is concentrated all in one month, and is zero if it is spread even across all months.  The **seasonal phase** is a measure of the peak of the season - it is not strictly the maximum monthly, but rather the average of all months when considering months as an angle in the complex plane.  

### Seasonal phase
```{r}
if(do_global_GPP & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          type = "values",
                          cuts = 0:12, 
                          override.cols = pals::ocean.phase(12),
                          ncol = num_cols,
                          map.overlay = map_overlay,   
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Phase differences
```{r}
if(do_global_GPP & doMapPlots){
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          cuts = seq(-6,6), 
                          symmetric.scale = FALSE,
                          ncol = num_cols,
                          map.overlay = map_overlay,    
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


### Seasonal concentration
```{r}
if(do_global_GPP & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Seasonal"]], 
                          type = "values",
                          ncol = num_cols,
                          map.overlay = map_overlay,            
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Concentration differences
```{r}
if(do_global_GPP & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Seasonal"]], 
                          ncol = num_cols,
                          map.overlay = map_overlay,           
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

## {.unlisted .unnumbered}

<a href="#top">Back to top</a>

***

# MODIS Leaf Area Index


```{r LAI data prep, echo=FALSE, out.width = '100%'}

if(do_global_LAI){
  
  # Currently only got one LAI dataset, but code as a list of data source for future flexibility
  LAI_data_Fields <- list()
  
  #### MODIS LAI SETTINGS AND DATA ####
  
  MODIS_LAI_monthly_dir <- "monthly_lai/MODIS"
  MODIS_LAI_monthly_file.name <- "MODIS_LAI.txt"
  MODIS_LAI_Source <- defineSource(id = "MODIS_LAI",
                                   name = "MODIS LAI",
                                   dir = file.path(params$data_directory, MODIS_LAI_monthly_dir),
                                   format = GUESS)
  
  full_file_path <- file.path(MODIS_LAI_Source@dir, MODIS_LAI_monthly_file.name)
  if(!file.exists(full_file_path)) {
    print("MODIS LAI data not available.")
  } else {
    LAI_data_Fields[[MODIS_LAI_Source@name]] <- getField(source = MODIS_LAI_Source,
                                                         quant = "mlai",
                                                         spatial.extent = spatial_extent,
                                                         spatial.extent.id = spatial_extent_id,
                                                         file.name = MODIS_LAI_monthly_file.name,
                                                         verbose = verbose_read)
  }
  
  
  #### PREPARE LAI BENCHMARK SETTINGS AND DATA ####
  
  if(length(LAI_data_Fields) == 0) {
    do_global_LAI <- FALSE
    print("Skipping LAI benchmark because no datasets available.")
  }
  else {
    
    # find overlapping years (general case if multiple datasets)
    first.year = last.year = NA
    for(this_Field in LAI_data_Fields) {
      first.year <- min(c(this_Field@first.year, first.year), na.rm = TRUE)
      last.year <- max(c(this_Field@last.year, last.year), na.rm = TRUE)
    }
    
    this_benchmark <- new("Benchmark",
                          id = "Global_LAI",
                          name = "Global LAI",
                          description = "Global leaf area",
                          simulation = "tellus",
                          guess_var = "mlai",
                          guess_layers = "mlai",
                          unit = "m^2^ m^-2^",
                          agg.unit = "Mm^2^",
                          datasets = LAI_data_Fields,
                          first.year = first.year,
                          last.year = last.year,
                          metrics = c("NME", "RMSE"))
    
    
    makeSummaryLine <- function(benchmark, col_names) {
      summary_table_lines <- as.list(rep("-", length(col_names)))
      names(summary_table_lines) <- col_names
      for(this_dataset in benchmark@datasets) {
        if(summary_table_lines$Dataset == "-") summary_table_lines$Dataset <- this_dataset@source@name
        else summary_table_lines$Dataset <- paste0(summary_table_lines$Dataset, ", ", this_dataset@source@name) 
      }
      summary_table_lines$Quantity <- benchmark@description
      summary_table_lines$Unit <- benchmark@agg.unit
      return(summary_table_lines)
    }
    summary_table_lines <- makeSummaryLine(this_benchmark, summary_col_names)
    
    
    
    ### Lists for storing the appropriate Fields and summary numbers
    all_LAI_Maps <- list()
    all_LAI_Trends <- list()
    all_LAI_Seasonal <- list()
    all_LAI_totals <- list()
    
    # Process the datasets according to the benchmark parameters above
    # this code will likely need to be adjusted depending on the details of variables, units, datasets etc
    for(this_data_Field in this_benchmark@datasets) {
      
      # crop the data to the comment benchmark year
      this_data_Field <- selectYears(this_data_Field, first = this_benchmark@first.year, last = this_benchmark@last.year)
      
      # delete values with -9999 and covert to kg
      this_data_Field@data <- this_data_Field@data[mlai != -9999.0,]
      
      # Calculate the slope (still in grams)
      all_LAI_Trends[[this_data_Field@source@name]] <- calcLinearTrend(this_data_Field)
      
      # make the annual map for comparison (leave only spatial)
      all_LAI_Maps[[this_data_Field@source@name]] <- aggregateYears(aggregateSubannual(this_data_Field, method = "max", target = "Year"), method = "mean")
      
      # make the seasonal cycle for comparison (leave months andspatial)
      all_LAI_Seasonal[[this_data_Field@source@name]] <- aggregateYears(this_data_Field, method = "mean")
      
      # make and save the mean annual global LAI
      # TODO, make this more flexible for multiple datasets
      data_LAI_MegaM2 <- areaWeightedTotal(all_LAI_Maps[[this_data_Field@source@name]], lon_centres = hd_lons, lat_centres = hd_lats)@data * M2_TO_MegaM2
      all_LAI_totals[[this_data_Field@source@name]] <- data_LAI_MegaM2
      summary_table_lines$Data <- signif(as.numeric(data_LAI_MegaM2), 4)
      
    }
    
    #### READ LPJ-GUESS DATA ####
    
    # loop through model runs to be processed
    for(this_sim_Source in all_simulation_Sources_list) {
      
      # check if file is present (if not don't include this run)
      this_benchmark_run_dir <- file.path(this_sim_Source@dir,this_benchmark@simulation)
      if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark@guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark@guess_var, ".out.gz")))) {
        
        # make local sources pointing to the simulation subrun directory
        this_subrun_Source <- this_sim_Source
        this_subrun_Source@dir <- this_benchmark_run_dir
        
        # read the full data and
        suppressWarnings(
          this_simulation_LAI <- getField(source = this_subrun_Source,
                                          this_benchmark@guess_var,
                                          spatial.extent = spatial_extent,
                                          spatial.extent.id = spatial_extent_id,
                                          first.year = this_benchmark@first.year,
                                          last.year = this_benchmark@last.year,  
                                          verbose = verbose_read,
                                          quick.read = quick_read,
                                          quick.read.file = paste(this_benchmark@guess_var, version_label, sep = "_"))
        )
        
        ### take sum of month and average of years and store for later use - very easy ###
        all_LAI_Maps[[this_sim_Source@name]] <- aggregateYears(aggregateSubannual(this_simulation_LAI, target = "Year", method = "max"),  "mean")
        
        ### take yearly average and store for later use - very easy ###
        all_LAI_Seasonal[[this_sim_Source@name]] <- aggregateYears(this_simulation_LAI, "mean")
        
        ### calculate and store the linear trend and p-value for every gridcell 
        all_LAI_Trends[[this_sim_Source@name]] <- calcLinearTrend(this_simulation_LAI)
        
        # calculate and save the global total
        this_LAI_MegaM2 <- areaWeightedTotal(all_LAI_Maps[[this_sim_Source@name]], lon_centres = hd_lons, lat_centres = hd_lats)@data * M2_TO_MegaM2
        all_LAI_totals[[this_sim_Source@name]] <- this_LAI_MegaM2
        summary_table_lines[[this_sim_Source@name]] <- signif(as.numeric(this_LAI_MegaM2),4)
        
        # remove to save memory
        rm(this_simulation_LAI)
        
      } # if file is present 
      else {
        do_global_LAI <- FALSE
      }
      
    } # for each model run
    
    
    # do all spatial comparisons and store them in a big list'o'lists to be plotted in the next code chunks
    all_LAI_comparisons <- fullSpatialComparison(this_benchmark, all_LAI_Maps, all_LAI_Trends, all_LAI_Seasonal, params$new_name, params$old_name)
    
    # save the summary table line 
    # TODO - add the data references
    names(summary_table_lines) <- names(summary_table)
    summary_table <- rbind(summary_table, summary_table_lines)
    
    # make mini metric table for this benchamrk and append to overall table
    metric_table <- rbind(metric_table, 
                          makeMetricTable(benchmark = this_benchmark, 
                                          all_comparisons_list = all_LAI_comparisons, 
                                          all_simulations_Sources_list = all_simulation_Sources_list))
    
    
  } # if data are available
  
} # if do_global_LAI
```



## Spatial patterns {.tabset}

### Absolute values
```{r}
if(do_global_LAI & doMapPlots){  
  # plot all absolute values together
  LAI_abs_values_plot <- plotSpatial(all_LAI_Maps, 
                                     ncol = num_cols, 
                                     legend.title = expression(m^{"2"}~m^{"-2"}),
                                     map.overlay = map_overlay,  
                                     title = "Absolute LAI values",
                                     limits = c(0,8),
                                     subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # add the total LAI to the plots
  total_label_df <- data.frame()
  for(this_panel in names(all_LAI_totals))  total_label_df <- rbind(total_label_df,
                                                                    list(label = paste(round(all_LAI_totals[[this_panel]], 1), "M m^2"), 
                                                                         Facet = this_panel, 
                                                                         x = stats_lon, y = stats_lat),
                                                                    stringsAsFactors = FALSE)
  total_label_df$Facet <- factor(total_label_df$Facet, levels = names(all_LAI_totals))
  LAI_abs_values_plot  <- LAI_abs_values_plot  + geom_text(data = total_label_df,  mapping = aes(x = x, y = y, label = label), size = 2.5)
  suppressWarnings(print(LAI_abs_values_plot))
}
```

### Differences

```{r}
if(do_global_LAI & doMapPlots){  
  LAI_diff_values_plot <- plotSpatialComparison(all_LAI_comparisons[["Values"]], 
                                                ncol = num_cols, 
                                                legend.title = expression(Delta~m^{"2"}~m^{"-2"}),
                                                map.overlay = map_overlay,             
                                                title = "LAI biases", 
                                                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # extract metric scores and add to the panels
  lat_offset = 0
  for(this_metric in this_benchmark@metrics) {
    metric_label_df <- data.frame()
    for(comparison_name  in names(all_LAI_comparisons[["Values"]])) {
      metric_label_df <- rbind(metric_label_df,
                               list(label = paste(this_metric, "=", round(all_LAI_comparisons[["Values"]][[comparison_name]]@stats[[this_metric]], 2)), 
                                    Facet = comparison_name, 
                                    x = stats_lon, y = stats_lat - lat_offset),
                               stringsAsFactors = FALSE)  
    }
    metric_label_df$Facet <- factor( metric_label_df$Facet, names(all_LAI_comparisons[["Values"]]))
    
    LAI_diff_values_plot  <- LAI_diff_values_plot  + geom_text(data = metric_label_df,  mapping = aes(x = x, y = y, label = label), size = 3)
    lat_offset <- lat_offset + 10  
  }
  
  suppressWarnings(print(LAI_diff_values_plot))
}
```



## Temporal trends {.tabset}

### Trend value
```{r}
if(do_global_LAI & doMapPlots) {
  suppressWarnings( print(
    plotSpatial(all_LAI_Trends, 
                layers = "Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.01,0.01),
                drop.cuts = FALSE,
                title = "Trend in LAI", 
                legend.title = expression(m^{"2"}~m^{"-2"}~month^{"-2"}),
                map.overlay = map_overlay,                  
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Trend significance
```{r}
if(do_global_LAI & doMapPlots) {
  suppressWarnings(print(
    plotSpatial(all_LAI_Trends, 
                layers = "p.value", 
                ncol = num_cols, 
                cols = viridis::turbo(6), 
                cuts = c(0, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0),
                drop.cuts = FALSE,
                title = "Significance in LAI Trends",
                legend.title =  "p value",
                map.overlay = map_overlay,                   
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}

```

### Trend Differences
```{r}
if(do_global_LAI & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Trend"]], 
                          ncol = num_cols, 
                          drop.cuts = NULL,
                          title = "Difference Trend in LAI", 
                          legend.title =  expression(m^{"2"}~m^{"-2"}~month^{"-2"}),
                          map.overlay = map_overlay,          
                          subtitle =paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
  
}
```


### Significant Trends
```{r}
if(do_global_LAI & doMapPlots) {
  suppressWarnings( print(
    plotSpatial(all_LAI_Trends, 
                layers = "Significant_Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.01,0.01),
                drop.cuts = FALSE,
                title = "Significant Trend in GPP (p-value < 0.05)", 
                legend.title = expression(expression(m^{"2"}~m^{"-2"}~month^{"-2"})),
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


## Seasonal analysis {.tabset}
Definition of seasonal concentration and phase follow Kelley *et al.* 2013.  **Seasonal concentration** equals one if the variable is concentrated all in one month, and is zero if it is spread even across all months.  The **seasonal phase** is a measure of the peak of the season - it is not strictly the maximum monthly, but rather the average of all months when considering months as an angle in the complex plane.  

### Seasonal phase
```{r}
if(do_global_LAI & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          type = "values",
                          cuts = 0:12, 
                          override.cols = pals::ocean.phase(12),
                          ncol = num_cols,
                          map.overlay = map_overlay,                   
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Phase differences
```{r}
if(do_global_LAI & doMapPlots){
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          cuts = seq(-6,6), 
                          symmetric.scale = FALSE,
                          ncol = num_cols,
                          map.overlay = map_overlay,                              
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


### Seasonal concentration
```{r}
if(do_global_LAI & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Seasonal"]], 
                          type = "values",
                          ncol = num_cols,
                          map.overlay = map_overlay,                          
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Concentration differences
```{r}
if(do_global_LAI & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Seasonal"]], 
                          ncol = num_cols,
                          map.overlay = map_overlay,                       
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

## {.unlisted .unnumbered}

<a href="#top">Back to top</a>

***

# Global burnt area 


```{r BA data prep, echo=FALSE, out.width = '100%'}
if(do_global_BA){
  
  ba.cuts <- c(0,0.002,0.005,0.01,0.02,0.05,0.10,0.2,0.50,1.0)
  ba.cols <- viridis::turbo(length(ba.cuts)-1)
  
  # Currently only got one burnt area dataset, but code as a list of data source for future flexibility
  BA_data_Fields <- list()
  
  #### GFED4 BA SETTINGS AND DATA ####
  
  GFED4_BA_monthly_dir <- "monthly_ba"
  GFED4_BA_monthly_file.name <- "GFED4.0_monthly_1996-2016.nc"
  GFED4_BA_Source <- defineSource(id = "GFED4_BA",
                                  name = "GFED4 BA",
                                  dir = file.path(params$data_directory, GFED4_BA_monthly_dir),
                                  format = NetCDF)
  
  full_file_path <- file.path(GFED4_BA_Source@dir, GFED4_BA_monthly_file.name)
  if(!file.exists(full_file_path)) {
    print("GFED4 BA data not available.")
  } else {
    BA_data_Fields[[GFED4_BA_Source@name]] <- suppressWarnings(getField(source = GFED4_BA_Source,
                                                                        quant = "burned_area_fraction",
                                                                        spatial.extent = spatial_extent,
                                                                        spatial.extent.id = spatial_extent_id,
                                                                        verbose = verbose_read,
                                                                        file.name = GFED4_BA_monthly_file.name))
  }
  
  
  #### PREPARE BA BENCHMARK SETTINGS AND DATA ####
  
  if(length(BA_data_Fields) == 0) {
    do_global_BA <- FALSE
    print("Skipping global burnt area benchmark because no datasets available.")
  }
  else {
    
    # find overlapping years (general case if multiple datasets)
    first.year = last.year = NA
    for(this_Field in BA_data_Fields) {
      first.year <- min(c(this_Field@first.year, first.year), na.rm = TRUE)
      last.year <- max(c(this_Field@last.year, last.year), na.rm = TRUE)
    }
    
    this_benchmark <- new("Benchmark",
                          id = "Global_BA",
                          name = "Global Burnt Area",
                          description = "Global burnt area",
                          simulation = "tellus",
                          guess_var = "monthly_burned_area",
                          guess_layers = "monthly_burned_area",
                          unit = "fraction",
                          agg.unit = "Mha",
                          datasets = BA_data_Fields,
                          first.year = first.year,
                          last.year = last.year,
                          metrics = c("NME", "RMSE"))
    
    
    makeSummaryLine <- function(benchmark, col_names) {
      summary_table_lines <- as.list(rep("-", length(col_names)))
      names(summary_table_lines) <- col_names
      for(this_dataset in benchmark@datasets) {
        if(summary_table_lines$Dataset == "-") summary_table_lines$Dataset <- this_dataset@source@name
        else summary_table_lines$Dataset <- paste0(summary_table_lines$Dataset, ", ", this_dataset@source@name) 
      }
      summary_table_lines$Quantity <- benchmark@description
      summary_table_lines$Unit <- benchmark@agg.unit
      return(summary_table_lines)
    }
    summary_table_lines <- makeSummaryLine(this_benchmark, summary_col_names)
    
    
    
    ### Lists for storing the appropriate Fields and summary numbers
    all_BA_Maps <- list()
    all_BA_Trends <- list()
    all_BA_Seasonal <- list()
    all_BA_totals <- list()
    
    # Process the datasets according to the benchmark parameters above
    # this code will likely need to be adjusted depending on the details of variables, units, datasets etc
    for(this_data_Field in this_benchmark@datasets) {
      
      # SPECIAL CASE for GFED4 data, remove gridcells that aren't in model gridlist
      if(this_data_Field@source@name == "GFED4 BA") {
        gridcells <- read.table(system.file("extdata", "Gridlist", "gridlist_global_0.5deg.txt", package = "DGVMBenchmarks"), header = TRUE)
        names(gridcells) <- c("Lon", "Lat")
        this_data_Field <- selectGridcells(this_data_Field, gridcells = gridcells, spatial.extent.id = "Global" )
      }
      
      # rename layer
      renameLayers(this_data_Field, this_benchmark@guess_var)
      
      # crop the data to the comment benchmark year
      this_data_Field <- selectYears(this_data_Field, first = this_benchmark@first.year, last = this_benchmark@last.year)
      
      # Calculate the slope (still in grams)
      all_BA_Trends[[this_data_Field@source@name]] <- calcLinearTrend(this_data_Field)
      
      # make the annual map for comparison (leave only spatial)
      all_BA_Maps[[this_data_Field@source@name]] <- aggregateYears(aggregateSubannual(this_data_Field, method = "sum", target = "Year"), method = "mean")
      
      # make the seasonal cycle for comparison (leave months andspatial)
      all_BA_Seasonal[[this_data_Field@source@name]] <- aggregateYears(this_data_Field, method = "mean")
      
      # make and save the mean annual global LAI
      # TODO, make this more flexible for multiple datasets
      data_BA_MHa <- areaWeightedTotal(all_BA_Maps[[this_data_Field@source@name]], lon_centres = hd_lons, lat_centres = hd_lats)@data * M2_TO_Mha
      all_BA_totals[[this_data_Field@source@name]] <- data_BA_MHa
      summary_table_lines$Data <- signif(as.numeric(data_BA_MHa),4)
      
    }
    
    #### READ LPJ-GUESS DATA ####
    
    # loop through model runs to be processed
    for(this_sim_Source in all_simulation_Sources_list) {
      
      # check if file is present (if not don't include this run)
      this_benchmark_run_dir <- file.path(this_sim_Source@dir,this_benchmark@simulation)
      if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark@guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark@guess_var, ".out.gz")))) {
        
        # make local sources pointing to the simulation subrun directory
        this_subrun_Source <- this_sim_Source
        this_subrun_Source@dir <- this_benchmark_run_dir
        
        # read the full data and
        suppressWarnings(
          this_simulation_BA <- getField(source = this_subrun_Source,
                                         this_benchmark@guess_var,
                                         spatial.extent = spatial_extent,
                                         spatial.extent.id = spatial_extent_id,
                                         first.year = this_benchmark@first.year,
                                         last.year = this_benchmark@last.year,
                                         verbose = verbose_read,
                                         quick.read = quick_read,
                                         quick.read.file = paste(this_benchmark@guess_var, version_label, sep = "_"))
        )
        
        ### take sum of month and average of years and store for later use - very easy ###
        all_BA_Maps[[this_sim_Source@name]] <- aggregateYears(aggregateSubannual(this_simulation_BA, target = "Year", method = "sum"),  "mean")
        
        ### take yearly average and store for later use - very easy ###
        all_BA_Seasonal[[this_sim_Source@name]] <- aggregateYears(this_simulation_BA, "mean")
        
        ### calculate and store the linear trend and p-value for every gridcell 
        all_BA_Trends[[this_sim_Source@name]] <- calcLinearTrend(this_simulation_BA)
        
        # calculate and save the global total
        this_BA_Mha <- areaWeightedTotal(all_BA_Maps[[this_sim_Source@name]], lon_centres = hd_lons, lat_centres = hd_lats)@data * M2_TO_Mha
        all_BA_totals[[this_sim_Source@name]] <- this_BA_Mha
        summary_table_lines[[this_sim_Source@name]] <- signif(as.numeric(this_BA_Mha),4)
        
        # remove to save memory
        rm(this_simulation_BA)
        
      } # if file is present 
      else {
        do_global_BA <- FALSE
      }
      
    } # for each model run
    
    # SPECIAL: for burnt area, convert trends in %/year
    for(this_trend in names(all_BA_Trends)) {
      all_BA_Trends[[this_trend]] <- layerOp(all_BA_Trends[[this_trend]], operator = "mulc", layers = "Trend", new.layer = "Trend", constant = 100*12) 
    }
    
    # do all spatial comparisons and store them in a big list'o'lists to be plotted in the next code chunks
    all_BA_comparisons <- fullSpatialComparison(this_benchmark, all_BA_Maps, all_BA_Trends, all_BA_Seasonal, params$new_name, params$old_name)
    
    # save the summary table line 
    # TODO - add the data references
    names(summary_table_lines) <- names(summary_table)
    summary_table <- rbind(summary_table, summary_table_lines)
    
    # make mini metric table for this benchamrk and append to overall table
    metric_table <- rbind(metric_table, 
                          makeMetricTable(benchmark = this_benchmark, 
                                          all_comparisons_list = all_BA_comparisons, 
                                          all_simulations_Sources_list = all_simulation_Sources_list))
    
    
  } # if data are available
  
} # if do_global_BA
```



## Spatial patterns {.tabset}

### Absolute values
```{r}
if(do_global_BA & doMapPlots){  
  # plot all absolute values together
  BA_abs_values_plot <- suppressWarnings(
    plotSpatial(all_BA_Maps, 
                ncol = num_cols, 
                legend.title = "fraction",
                map.overlay = map_overlay,  
                title = "Absolute burnt fraction values",
                cuts = ba.cuts,
                cols = ba.cols,
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  )
  
  # add the total BA to the plots
  total_label_df <- data.frame()
  for(this_panel in names(all_BA_totals))  total_label_df <- rbind(total_label_df,
                                                                   list(label = paste(round(all_BA_totals[[this_panel]], 1), this_benchmark@agg.unit), 
                                                                        Facet = this_panel, 
                                                                        x = stats_lon, y = stats_lat),
                                                                   stringsAsFactors = FALSE)
  total_label_df$Facet <- factor(total_label_df$Facet, levels = names(all_BA_totals))
  BA_abs_values_plot  <- BA_abs_values_plot  + geom_text(data = total_label_df,  mapping = aes(x = x, y = y, label = label), size = 2.5)
  suppressWarnings(print(BA_abs_values_plot))
}
```

### Differences

```{r}
if(do_global_BA & doMapPlots){  
  BA_diff_values_plot <- plotSpatialComparison(all_BA_comparisons[["Values"]], 
                                               ncol = num_cols, 
                                               legend.title = expression(Delta~"fraction"),
                                               map.overlay = map_overlay,             
                                               title = "BA biases", 
                                               subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # extract metric scores and add to the panels
  lat_offset = 0
  for(this_metric in this_benchmark@metrics) {
    metric_label_df <- data.frame()
    for(comparison_name  in names(all_BA_comparisons[["Values"]])) {
      metric_label_df <- rbind(metric_label_df,
                               list(label = paste(this_metric, "=", round(all_BA_comparisons[["Values"]][[comparison_name]]@stats[[this_metric]], 2)), 
                                    Facet = comparison_name, 
                                    x = stats_lon, y = stats_lat - lat_offset),
                               stringsAsFactors = FALSE)  
    }
    metric_label_df$Facet <- factor( metric_label_df$Facet, names(all_BA_comparisons[["Values"]]))
    
    BA_diff_values_plot  <- BA_diff_values_plot  + geom_text(data = metric_label_df,  mapping = aes(x = x, y = y, label = label), size = 3)
    lat_offset <- lat_offset + 10  
  }
  
  suppressWarnings(print(BA_diff_values_plot))
}
```



## Temporal trends {.tabset}

### Trend value
```{r}
if(do_global_BA & doMapPlots) {
  suppressWarnings( print(
    plotSpatial(all_BA_Trends, 
                layers = "Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.3,0.3),
                drop.cuts = FALSE,
                title = "Trend in BA", 
                legend.title =  expression('%'~year^{"-1"}),
                map.overlay = map_overlay,                  
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Trend significance
```{r}
if(do_global_BA & doMapPlots) {
  suppressWarnings(print(
    plotSpatial(all_BA_Trends, 
                layers = "p.value", 
                ncol = num_cols, 
                cols = viridis::turbo(6), 
                cuts = c(0, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0),
                drop.cuts = FALSE,
                title = "Significance in BA Trends",
                legend.title =  "p value",
                map.overlay = map_overlay,                   
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}

```

### Trend Differences
```{r}
if(do_global_BA & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_BA_comparisons[["Trend"]], 
                          ncol = num_cols, 
                          drop.cuts = NULL,
                          title = "Difference Trend in BA", 
                          legend.title =  expression(Delta ~ '%'~year^{"-1"}),
                          map.overlay = map_overlay,          
                          subtitle =paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
  
}
```


### Significant Trends
```{r}
if(do_global_BA & doMapPlots) {
  suppressWarnings( print(
    plotSpatial(all_BA_Trends, 
                layers = "Significant_Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.3,0.3),
                drop.cuts = FALSE,
                title = "Significant Trend in burnt area (p-value < 0.05)", 
                legend.title = expression('%'~year^{"-1"}),
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


## Seasonal analysis {.tabset}
Definition of seasonal concentration and phase follow Kelley *et al.* 2013.  **Seasonal concentration** equals one if the variable is concentrated all in one month, and is zero if it is spread even across all months.  The **seasonal phase** is a measure of the peak of the season - it is not strictly the maximum monthly, but rather the average of all months when considering months as an angle in the complex plane.  

### Seasonal phase
```{r}
if(do_global_BA & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_BA_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          type = "values",
                          cuts = 0:12, 
                          override.cols = pals::ocean.phase(12),
                          ncol = num_cols,
                          map.overlay = map_overlay,                   
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Phase differences
```{r}
if(do_global_BA & doMapPlots){
  suppressWarnings(print(
    plotSpatialComparison(all_BA_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          override.cols =  colorRampPalette(colors = c("black", "blue", "white", "red", "black"))(11),
                          cuts = c(-6, -4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 6.0),
                          symmetric.scale = FALSE,
                          ncol = num_cols,
                          map.overlay = map_overlay,                              
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


### Seasonal concentration
```{r}
if(do_global_BA & doMapPlots ) {
  suppressWarnings(print(
    plotSpatialComparison(all_BA_comparisons[["Seasonal"]], 
                          type = "values",
                          ncol = num_cols,
                          map.overlay = map_overlay,                          
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Concentration differences
```{r}
if(do_global_BA & doMapPlots) {
  suppressWarnings(print(
    plotSpatialComparison(all_BA_comparisons[["Seasonal"]], 
                          ncol = num_cols,
                          map.overlay = map_overlay,                       
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

## {.unlisted .unnumbered}

<a href="#top">Back to top</a>

***


# Pan forest biomass



```{r Pan biomass data prep, echo=FALSE, out.width = '100%'}


#### Pan Biomass Data Prep ####

if(do_Pan_Biomass){
  
  ### Here we read the model and data for both the spatial and trend analyses (which are actually done in the next code blocks)
  
  ### some parameters and settings
  guess_var <- "cpool_natural"
  dataset_first_year <- 2007
  dataset_last_year <- 2007
  this_data_dir <- "Biomass"
  this_data_file_name <-  "pan_regional_data_reformatted.txt"
  this_gridlist_file_name <- "gridlist_pan_gfed_ISO3_UN.csv"
  dataset_id <- "Pan_2007"
  dataset_name <- "Pan forest biomass"
  this_unit <- "C"
  benchmark_description <- "Pan forest biomass"
  
  
  
  # read the regions for subsetting
  regions_file_path <- file.path( system.file("extdata", "Gridlist", package = "DGVMBenchmarks"), this_gridlist_file_name) 
  regions_dt <- fread(regions_file_path)
  
  
  
  #### READ PAN REGIONAL BIOMASS DATA ####
  
  full_file_path <- file.path( system.file("extdata", "Biomass", package = "DGVMBenchmarks"), this_data_file_name) 
  
  if(file.exists(full_file_path)) {
    
    # read data, make global and total sums, and reformat 
    suppressWarnings( # suppresses warning about "<" not being valid for factors
      fread(full_file_path, quote = "") %>% 
        mutate(Global = Russia+Canada+N_Europe+USA+Europe+China+Japan+S_Korea+Australia+NZ+S_Asia+Africa+Americas) %>%
        melt.data.table(id.vars = c("Pool","Year")) %>% 
        dcast( ... ~ Pool) %>% 
        setnames(c("variable", "LIT", "SOI", "TLB"), c("Region", "LitterC", "SoilC", "VegC")) %>%
        mutate(across(everything(), function(x){replace(x, which(x<0), NA)}))  %>%
        mutate(Total = LitterC + SoilC + VegC + DWD) -> pan_dt
    )
    
  }
  
  
  
  #### READ LPJ-GUESS LAI DATA ####
  
  all_Model_Biomass_Fields <- list()
  
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    this_benchmark_run_dir <- file.path(this_sim_Source@dir, this_benchmark@simulation)
    if(file.exists(file.path(this_benchmark_run_dir, paste0(guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(guess_var, ".out.gz")))) {
      
      # make local sources pointing to the simulation subrun directory
      this_subrun_Source <- this_sim_Source
      this_subrun_Source@dir <- this_benchmark_run_dir
      
      # read the full data and
      suppressWarnings(
        this_simulation_Field <- getField(source = this_subrun_Source,
                                          guess_var,
                                          first.year = dataset_first_year, # TODO +/-3
                                          last.year = dataset_last_year,
                                          verbose = verbose_read,
                                          quick.read = quick_read,
                                          quick.read.file = paste(guess_var, version_label, sep = "_"))
      )
      
      # tide columns and make Total without harvest
      layerOp(this_simulation_Field, NULL, "HarvSlowC")
      layerOp(this_simulation_Field, "+", c("VegC", "LitterC", "SoilC"), "Total")
      
      # save
      all_Model_Biomass_Fields[[this_subrun_Source@name]]  <- this_simulation_Field
      
      # remove to save memory
      rm(this_simulation_Field)
      
      
    } # if file is present 
    
    # combine tables
    
    # print table
    
  } # for each model run
  
  # Build a data and model table based in the data table
  
  pan_2007_dt <- pan_dt[Year == 2007, ]
  pan_2007_dt[, Year := NULL]
  pan_2007_dt[, Source := "Pan 2007"]
  
  final_dt <- data.table()
  for(this_row_number in 1:nrow(pan_2007_dt)) {
    
    # add the data
    final_dt <- rbind(final_dt, pan_2007_dt[this_row_number ,])
    
    # get the region and associated gridcells 
    this_region <- pan_2007_dt[this_row_number ,][["Region"]]
    if(this_region == "S_Korea") this_region <- "South_Korea"
    if(this_region == "NZ") this_region <- "New_Zealand"
    if(this_region == "S_Asia") this_region <- "South_Asia"
    if(this_region != "Global") {this_region_gridcells <- regions_dt[Pan_2007 == this_region, .(Lon, Lat)]}
    else{this_region_gridcells <- regions_dt[, .(Lon, Lat)]}
    
    # for each simulation
    for(this_sim_Source in all_simulation_Sources_list) {
      
      this_sim_region <- selectGridcells(all_Model_Biomass_Fields[[this_sim_Source@name]], this_region_gridcells, as.character(this_region))
      this_sim_region_summed <- aggregateSpatial(this_sim_region, method = "w.sum", lon_centres = hd_lons, lat_centres = hd_lats)    
      this_line <- this_sim_region_summed@data
      this_line[, Year := NULL]
      this_line[, VegC := VegC *KG_TO_PG ]
      this_line[, LitterC := LitterC *KG_TO_PG ]
      this_line[, SoilC := SoilC *KG_TO_PG ]
      this_line[, Total := Total *KG_TO_PG ]
      this_line[, Source := this_sim_Source@name]
      final_dt <-rbind(final_dt, this_line, fill = TRUE)
      
    }
  }
  
  # order columns and print
  setcolorder(final_dt, c( "Region", "Source", "LitterC", "SoilC", "VegC", "DWD", "Total"   ))
  kable(final_dt, digits = 1, align = "l") %>% kable_classic( html_font = "Cambria", bootstrap_options = c("striped", "hover", "condensed"))
  
  
} # if do_Pan
```

<a href="#top">Back to top</a>

***

# Regrowth

Maybe some description and data references etc here.

```{r regrowth, echo=FALSE, out.width = '100%'}

#### Regrowth Data Prep ####
if(do_Regrowth){
  
  # read the regrowth data
  
  # first the gridlist
  input_dir <- system.file("extdata", "Regrowth", package = "DGVMBenchmarks")
  gridlist_file <- file.path(input_dir, "gridlist.txt")
  gridlist <- read.table(gridlist_file)
  names(gridlist) <- c("Lon","Lat","distyear","Biome")
  
  # now the data
  regrowth_file <- file.path(input_dir, "benchmark_regrowth_08022023.csv")
  regrowth <- read.csv(file =regrowth_file)
  
  
  regrowth_full_dt <- data.table(regrowth)[, list(new_bin, bin_num, AGcwood_kgCm2_med, AGcwood_kgCm2_10, AGcwood_kgCm2_90, Biome)]
  regrowth_full_dt[, bin_centres := as.factor(bin_num)]
  regrowth_full_dt$Source <- "Data"
  
  # define the benchmark
  this_benchmark <- new("Benchmark",
                        id = "Regrowth",
                        name = "Regrowth",
                        description = "Regrowth",
                        simulation = "regrowth",
                        guess_var = "cmass",
                        guess_layers = "Total",
                        unit = "kgC/m^2",
                        agg.unit = "Not USed",
                        datasets = regrowth,
                        first.year = 0,
                        last.year = 150,
                        metrics = character(0))
  
  # read the model output
  # loop through model runs to be processed
  all_Regrowth_Fields <- list()
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    this_benchmark_run_dir <- file.path(this_sim_Source@dir,this_benchmark@simulation)
    if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark@guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark@guess_var, ".out.gz")))) {
      
      # make local sources pointing to the simulation subrun directory
      this_regrowth_Source <- this_sim_Source
      this_regrowth_Source@dir <- this_benchmark_run_dir
      
      # read the full data and
      suppressWarnings(
        this_simulation_regrowth <- getField(source = this_regrowth_Source,
                                             this_benchmark@guess_var,
                                             verbose = verbose_read,
                                             quick.read = quick_read,
                                             quick.read.file = paste(this_benchmark@guess_var, version_label, sep = "_"))
      )
      
      
      #merge with gridcell to find disturbance year, needed to reconstruct stand age
      model_joined <- inner_join(this_simulation_regrowth@data, gridlist)
      
      #introduce some new variables, Age, age-bins and summary stats:
      model_joined <- model_joined %>% select(Lat,Lon,Year,Total,Forest_sum,Natural_sum,distyear,Biome)
      model_regr <- model_joined %>% group_by(Lat,Lon) %>% filter(Year >= distyear)
      age <- model_regr %>% group_by(Lat,Lon) %>% mutate(Age = Year - distyear)
      age_bins <- age %>% group_by(Lat,Lon) %>% mutate(new_bin = cut(Age, breaks=seq(0,300,10),include.lowest = TRUE,ordered_result = TRUE))
      #remove entries where the number of sites which achieve this stand age is lower than 10.
      counts_filtered <- age_bins %>% group_by(Biome,Age) %>% mutate(count= n()) %>% filter(count > 10) 
      
      
      #summary stats on bins:
      regrowth_mod_full <- counts_filtered %>% group_by(new_bin, Biome) %>% summarise(AGcwood_kgCm2_med = median(Total),
                                                                                      AGcwood_kgCm2_10 = quantile(Total, c(.10) ),
                                                                                      AGcwood_kgCm2_90 = quantile(Total, c(.90) ),
                                                                                      bin_centres =  floor(mean(Age))) 
      
      
      regrowth_mod_full$Source <- this_regrowth_Source@name
      regrowth_full_dt <- rbindlist(list(regrowth_full_dt, regrowth_mod_full), fill = TRUE)
      
    } # if output file exists
    
  } # for each simulation
  
  # set bin centres
  regrowth_full_dt[, bin_centres := as.numeric(as.character(bin_centres))]
  
  # and finally plot
  regrowth_plot <- ggplot(regrowth_full_dt, aes(x=bin_centres)) + geom_point(aes(y = AGcwood_kgCm2_med,
                                                                                 col = Source)) +
    geom_errorbar(aes(ymin=AGcwood_kgCm2_10, ymax=AGcwood_kgCm2_90, col = Source)) +
    facet_wrap(~Biome, ncol = 2, scales = "fixed" ) +
    labs(x= "Years after disturbance", y = expression(AG~wood~kgC~m^{"-2"})) # + geom_hline(yintercept = 10, col = "grey")
  
  print(regrowth_plot)
  
}
```


<a href="#top">Back to top</a>

***

# Global Biomass


```{r Global biomass prep, echo=FALSE, out.width = '100%'}

#### Global Biomass Data Prep ####
if(do_Global_Biomass){
  
  ### Lists for storing the field and totals
  all_Biomass_Maps <- list()
  Biome_Map_Fields_list <- list()  # only for simulation for the totle-to-aboveground biome-specific correction
  all_Biomass_totals <- list()
  
  this_benchmark <- new("Benchmark",
                        id = "Global_Biomas",
                        name = "Global Biomass",
                        description = "Global Aboveground Biomass",
                        simulation = "tellus",
                        guess_var = "cmass",
                        guess_layers = c("Crop_sum", "Pasture_sum", "Natural_sum"),
                        unit = "kg m^-2^",
                        agg.unit = "PgC",
                        datasets = list(),
                        first.year = 1993,
                        last.year = 2012,
                        metrics = c("NME", "RMSE"))
  
  
  #### READ THE LUI DATA #### 
  
  ### the benchmarking datasets for global biomass
  liu_biomass = list(
    dataset_id = "Liu_biomass",
    dataset_name = "Liu biomass",
    first_year = 1993,
    last_year = 2012,
    this_data_dir = "biomass/Liu_1993-2012",
    this_data_file_name = "Global_mean_ABC_1993-2012_Liu2015_SI.dat",
    id = "liu",
    name = "Liu global biomass",
    this_unit = "kg/m2"
  )
  
  full_file_path <- file.path(params$data_directory, liu_biomass$this_data_dir, liu_biomass$this_data_file_name)
  if(file.exists(full_file_path)) {
    
    # Read th data via a GUESS formatted Source
    data_Source <- defineSource(id = liu_biomass$dataset_id,
                                name = liu_biomass$dataset_name,
                                dir = file.path(params$data_directory, liu_biomass$this_data_dir),
                                format = GUESS)
    suppressWarnings(
      this_data_Field <- getField(source = data_Source,
                                  quant = this_benchmark@guess_var,
                                  spatial.extent = spatial_extent,
                                  spatial.extent.id = spatial_extent_id,
                                  verbose = verbose_read,
                                  file.name = liu_biomass$this_data_file_name)
    )
    
    # correct metadata and save
    this_data_Field@first.year <- liu_biomass$first_year
    this_data_Field@last.year <- liu_biomass$last_year
    this_data_Field@year.aggregate.method <- "mean"
    this_data_Field@id <- makeFieldID(this_data_Field)
    this_data_Field <- renameLayers(this_data_Field, this_benchmark@guess_var)
    all_Biomass_Maps[[this_data_Field@source@name]] <- this_data_Field
    
    # calculate the global total
    all_Biomass_totals[[this_data_Field@source@name]] <- areaWeightedTotal(this_data_Field, lon_centres = hd_lons, lat_centres = hd_lats)@data * KG_TO_PG
    # calculate the global total
    this_Biomass_total_PgC  <- areaWeightedTotal(this_data_Field, lon_centres = hd_lons, lat_centres = hd_lats)@data * KG_TO_PG
    all_Biomass_totals[[this_data_Field@source@name]] <- this_Biomass_total_PgC
    
    # make the summary table lines
    this_benchmark@datasets <- list(this_data_Field)
    summary_table_lines <- makeSummaryLine(this_benchmark, summary_col_names)
    summary_table_lines$Data <- signif(as.numeric(this_Biomass_total_PgC),4)
    
  }
  
  # no loop just use the Liu data
  this_dataset <- liu_biomass
  
  #### READ LPJ-GUESS BIOMASS DATA ####
  
  # read and process the land cover data required for weighting the LPJ-GUESS output
  all_lc_dt <- fread(params$land_cover_file)
  all_lc_dt <- all_lc_dt[Year >= liu_biomass$first_year & Year <= liu_biomass$last_year,]
  final_lc_dt <- all_lc_dt[,lapply(.SD,mean),by=.(Lon, Lat)]
  final_lc_dt[, Year := NULL]
  
  
  
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    this_benchmark_run_dir <- file.path(this_sim_Source@dir, this_benchmark@simulation)
    if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark@guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark@guess_var, ".out.gz")))) {
      
      # read the full data and
      temp_simulation_Source <- this_sim_Source
      temp_simulation_Source@dir <- this_benchmark_run_dir
      suppressWarnings(
        this_cmass <- getField(source = temp_simulation_Source,
                               quant = this_benchmark@guess_var,
                               spatial.extent = spatial_extent,
                               spatial.extent.id = spatial_extent_id,
                               first.year = this_dataset$first_year,
                               last.year = this_dataset$last_year,
                               year.aggregate.method = "mean",
                               verbose = verbose_read,
                               quick.read = quick_read,
                               quick.read.file = paste(this_benchmark@guess_var, version_label, sep = "_"),
                               layers = this_benchmark@guess_layers)
      )
      
      # get the biomes for the correction
      suppressWarnings(
        this_biomes <- getScheme(source = temp_simulation_Source,
                                 scheme = Smith2014BiomeScheme,
                                 spatial.extent = spatial_extent,
                                 spatial.extent.id = spatial_extent_id,
                                 first.year = this_dataset$first_year,
                                 last.year = this_dataset$last_year,
                                 year.aggregate.method = "mean",
                                 quick.read = quick_read,
                                 quick.read.file = paste(this_benchmark@guess_var,version_label, sep = "_"))
      )
      
      
      ### MF: Copied verbatim from postprocess_above_ground_biomass.sh to serve as documentation
      
      # Above-ground biomass percentages following Jackson et al. 1996                                                                                                                                           
      # BF=0.75        # boreal forest  
      # CROPS=0.9
      # DESERT=0.18
      # ScS=0.45       # Sclerophyllous Shrubs
      # TeCF=0.85      # Temp coniferous forest 
      # TeDF=0.81      # Temp deciduous forest
      # TeG=0.21       # Temp grassland  
      # TrDF=0.75      # Tropical deciduous forest   
      # TrEF=0.84      # Tropical evergreen forest
      # TrGS=0.59      # Tropical grassland savanna 
      # TU=0.13        # Tundra    
      # Hickler Coding -> Jackson Coding:       
      #  1 Boreal decid forest  -> BF     
      #  2 Boreal ever forest   -> BF
      #  3 Temp/boreal mix fo.  -> TeDF 
      #  4 Temp conifer forest  -> TeCF  
      #  5 Temp decid forest    -> TeDF    
      #  6 Temp broad ever fo.  -> TeDF     
      #  7 Temp mixed forest    -> 1/2(TeDF+TeCF)   
      #  8 Trop season forest   -> 1/2(TrDF+TrEF)   
      #  9 Trop rain forest     -> TrEF    
      # 10 Trop decid forest    -> TrDF     
      # 11 Moist savannas       -> TrGS      
      # 12 Dry savannas         -> TrGS    
      # 13 Tall grassland       -> TeG  
      # 14 Dry grassland        -> TeG   
      # 15 Xeric wood/shrub     -> ScS    
      # 16 Arid shrub/steppe    -> ScS     
      # 17 Desert               -> DESERT     
      # 18 Arctic/alpine tundra -> TU    
      
      # Based on the above I define the following lookup table for the biomes
      biome_abg_lookup <- c(
        "Boreal Deciduous Forest/Woodland" = 0.75,
        "Boreal Evergreen Forest/Woodland" = 0.75,
        "Temperate/Boreal Mixed Forest" = 0.81,
        "Temperate Conifer Forest" = 0.85, # MF - NOTE:not present in biome scheme
        "Temperate Deciduous Forest" = 0.85,
        "Temperate Broadleaved Evergreen Forest" = 0.81,
        "Temperate Mixed Forest" = (0.85+0.81)/2,
        "Tropical Seasonal Forest" = (0.75+0.84)/2,
        "Tropical Rain Forest" = 0.84,
        "Tropical Deciduous Forest"= 0.75,
        "Moist Savanna" = 0.59,
        "Dry Savanna" = 0.59,
        "Tall Grassland" = 0.21,
        "Dry Grassland" = 0.21,
        "Xeric Woodland/Shrubland" = 0.45,
        "Arid Shrubland/Steppe" = 0.45,
        "Desert" = 0.18,
        "Arctic/Alpine Tundra" = 0.13
      )
      
      # first crops - easy
      this_cmass <- layerOp(this_cmass, "mulc", "Crop_sum", new.layer = "Crop_sum", constant = 0.9)
      
      # second pasture - outside +/-24 use temerate grasses, inside use tropical grasses
      pasture_abg_fraction <- function(lat) {
        ifelse(abs(lat) < 24, 0.59, 0.21)
      }
      this_cmass@data <- this_cmass@data[, Pasture_multiplier := pasture_abg_fraction(Lat)]
      layerOp(this_cmass, operator = "*", layers = c("Pasture_sum", "Pasture_multiplier"), new.layer = "Pasture_sum")
      layerOp(this_cmass, operator = NULL, "Pasture_multiplier")
      
      # third natural - look up biome specific multiplier
      biomes_dt <- this_biomes@data[ , Natural_multiplier := biome_abg_lookup[Smith2014]]
      this_cmass <- copyLayers(from = biomes_dt, to = this_cmass, layer.names = "Natural_multiplier")
      layerOp(this_cmass, operator =  "*", layers = c("Natural_sum", "Natural_multiplier"), new.layer ="Natural_sum" )
      layerOp(this_cmass, operator =  NULL, layers = "Natural_multiplier")
      
      # last step, weight the landcover types by their fraction 
      this_cmass <- copyLayers(from = final_lc_dt,
                               to = this_cmass,
                               layer.names = c("NATURAL", "PASTURE", "CROPLAND"), 
                               keep.all.from = FALSE,
                               keep.all.to = FALSE)
      this_cmass <- layerOp(this_cmass, "*", c("NATURAL", "Natural_sum"),  "Natural_sum")
      this_cmass <- layerOp(this_cmass, "*", c("PASTURE", "Pasture_sum"),  "Pasture_sum")
      this_cmass <- layerOp(this_cmass, "*", c("CROPLAND", "Crop_sum"),  "Crop_sum")
      this_cmass <- layerOp(this_cmass, "+", c("Natural_sum", "Pasture_sum", "Crop_sum"),  this_benchmark@guess_var)
      all_Biomass_Maps[[this_sim_Source@name]] <- selectLayers(this_cmass, this_benchmark@guess_var)
      
      # calculate the global total
      this_Biomass_total_PgC  <-areaWeightedTotal(all_Biomass_Maps[[this_sim_Source@name]], lon_centres = hd_lons, lat_centres = hd_lats)@data * KG_TO_PG
      all_Biomass_totals[[this_sim_Source@name]] <- this_Biomass_total_PgC
      summary_table_lines[[this_sim_Source@name]] <- signif(as.numeric(this_Biomass_total_PgC),4)
      
    } # if file is present 
    else {
      message("No modelled biomass file found, benchmark will be skipped.")
      do_Global_biomass <- FALSE
    }
    
  } # for each model run
  
  # do biomass spatial comparisons and store to be plotted in the next code chunks
  all_Biomass_comparisons <- fullSpatialComparison(this_benchmark, all_maps = all_Biomass_Maps, new_model = params$new_name, old_model = params$old_name)
  
  # save the summary table line 
  # TODO - add the data references
  names(summary_table_lines) <- names(summary_table)
  summary_table <- rbind(summary_table, summary_table_lines)
  
  # make mini metric table for this benchamrk and append to overall table
  metric_table <- rbind(metric_table, 
                        makeMetricTable(benchmark = this_benchmark, 
                                        all_comparisons_list = all_Biomass_comparisons, 
                                        all_simulations_Sources_list = all_simulation_Sources_list))
  
  
} # if do_Global_Biomass



```


## Spatial patterns {.tabset}

### Absolute values
```{r}
if(do_Global_Biomass & doMapPlots){  
  # plot all absolute values together
  Biomass_abs_values_plot <- plotSpatial(all_Biomass_Maps, 
                                         ncol = num_cols, 
                                         legend.title = expression(kg~m^{"-2"}),
                                         map.overlay = map_overlay,  
                                         title = "Absolute Biomass values",
                                         limits = c(0,25),
                                         subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # add the total LAI to the plots
  total_label_df <- data.frame()
  for(this_panel in names(all_Biomass_totals))  total_label_df <- rbind(total_label_df,
                                                                        list(label = paste(round(all_Biomass_totals[[this_panel]], 1), this_benchmark@agg.unit), 
                                                                             Facet = this_panel, 
                                                                             x = stats_lon, y = stats_lat),
                                                                        stringsAsFactors = FALSE)
  total_label_df$Facet <- factor(total_label_df$Facet, levels = names(all_Biomass_totals))
  Biomass_abs_values_plot  <- Biomass_abs_values_plot  + geom_text(data = total_label_df,  mapping = aes(x = x, y = y, label = label), size = 2.5)
  suppressWarnings(print(Biomass_abs_values_plot))
}
```

### Differences

```{r}
if(do_Global_Biomass & doMapPlots){  
  Biomass_diff_values_plot <- plotSpatialComparison(all_Biomass_comparisons[["Values"]], 
                                                    ncol = num_cols, 
                                                    legend.title = expression(Delta~kg~m^{"-2"}),
                                                    map.overlay = map_overlay,             
                                                    title = "Biomass biases", 
                                                    subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # extract metric scores and add to the panels
  lat_offset = 0
  for(this_metric in this_benchmark@metrics) {
    metric_label_df <- data.frame()
    for(comparison_name  in names(all_Biomass_comparisons[["Values"]])) {
      metric_label_df <- rbind(metric_label_df,
                               list(label = paste(this_metric, "=", round(all_Biomass_comparisons[["Values"]][[comparison_name]]@stats[[this_metric]], 2)), 
                                    Facet = comparison_name, 
                                    x = stats_lon, y = stats_lat - lat_offset),
                               stringsAsFactors = FALSE)  
    }
    metric_label_df$Facet <- factor( metric_label_df$Facet, names(all_Biomass_comparisons[["Values"]]))
    
    Biomass_diff_values_plot  <- Biomass_diff_values_plot  + geom_text(data = metric_label_df,  mapping = aes(x = x, y = y, label = label), size = 3)
    lat_offset <- lat_offset + 10  
  }
  
  suppressWarnings(print(Biomass_diff_values_plot))
}
```


## {.unlisted .unnumbered}

<a href="#top">Back to top</a>

***


# Global Summary Tables

## Inter-model comparisons {.tabset}

###  C Fluxes (Pg C/y)

``` {r C fluxes table, echo=FALSE, out.width = '100%', out.height= '150%'}
if(do_Global_Summary_Tables) {
  this_complete_df <- modelSummaryTable(simulations = all_simulation_Sources_list, 
                                        var = "cflux", 
                                        periods = summary_periods, 
                                        new_sim =  params$new_name, 
                                        old_sim = params$old_name, 
                                        spatial_extent = spatial_extent,
                                        spatial_extent_id = spatial_extent_id,
                                        area_unit = "m^2",
                                        unit_multiplier = KG_TO_PG)
  if(nrow(this_complete_df) > 0) {
    kable(this_complete_df) %>% kable_styling(full_width = TRUE)
  }
}
```



###  N Fluxes (Tg N/y)

``` {r N fluxes table, echo=FALSE, out.width = '100%', out.height= '150%'}
if(do_Global_Summary_Tables) {
  this_complete_df <- modelSummaryTable(simulations = all_simulation_Sources_list, 
                                        var = "nflux", 
                                        periods = summary_periods, 
                                        new_sim =  params$new_name, 
                                        old_sim = params$old_name, 
                                        spatial_extent = spatial_extent,
                                        spatial_extent_id = spatial_extent_id,
                                        area_unit = "ha",
                                        unit_multiplier = KG_TO_TG)
  if(nrow(this_complete_df) > 0) {
    kable(this_complete_df) %>% kable_styling(full_width = TRUE)
  }
}
```


###  C Pools (Pg C)

``` {r C pools table, echo=FALSE, out.width = '100%', out.height= '150%'}
if(do_Global_Summary_Tables) {
  this_complete_df <- modelSummaryTable(simulations = all_simulation_Sources_list, 
                                        var = "cpool", 
                                        periods = summary_periods, 
                                        new_sim =  params$new_name, 
                                        old_sim = params$old_name, 
                                        spatial_extent = spatial_extent,
                                        spatial_extent_id = spatial_extent_id,
                                        area_unit = "m^2",
                                        unit_multiplier = KG_TO_PG)
  if(nrow(this_complete_df) > 0) {
    kable(this_complete_df) %>% kable_styling(full_width = TRUE)
  }
}
```

###  N Pools (Pg N)

``` {r N pools table, echo=FALSE, out.width = '100%', out.height= '150%'}
if(do_Global_Summary_Tables) {
  this_complete_df <- modelSummaryTable(simulations = all_simulation_Sources_list, 
                                        var = "npool", 
                                        periods = summary_periods, 
                                        new_sim =  params$new_name, 
                                        old_sim = params$old_name, 
                                        spatial_extent = spatial_extent,
                                        spatial_extent_id = spatial_extent_id,
                                        area_unit = "m^2",
                                        unit_multiplier = KG_TO_PG)
  if(nrow(this_complete_df) > 0) {
    kable(this_complete_df) %>% kable_styling(full_width = TRUE)
  }
}
```


### Run-off (km^3^ H~2~O/y)

``` {r Total runoff table, echo=FALSE, out.width = '100%', out.height= '150%'}
if(do_Global_Summary_Tables) {
  this_complete_df <- modelSummaryTable(simulations = all_simulation_Sources_list, 
                                        var = "tot_runoff", 
                                        periods = summary_periods, 
                                        new_sim =  params$new_name, 
                                        old_sim = params$old_name, 
                                        spatial_extent = spatial_extent,
                                        spatial_extent_id = spatial_extent_id,
                                        area_unit = "m^2",
                                        unit_multiplier = KG_TO_PG)
  if(nrow(this_complete_df) > 0) {
    kable(this_complete_df) %>% kable_styling(full_width = TRUE)
  }
}
```



## Data comparisons

TABLE FORMATTING: see here: [https://rmarkdown.rstudio.com/lesson-7.html](https://rmarkdown.rstudio.com/lesson-7.html)


``` {r Global summary, echo=FALSE, out.width = '100%', out.height= '150%'}


# get the global soil N2O flux for the summary table
# for 2000-2010 to compare to the IPCC AR5 values
this_soil_N2O_df <- modelSummaryTable(simulations = all_simulation_Sources_list, 
                                      var = "soil_nflux", 
                                      periods = list(c(2000,2010)), 
                                      new_sim =  params$new_name, 
                                      old_sim = params$old_name, 
                                      spatial_extent = spatial_extent,
                                      spatial_extent_id = spatial_extent_id,
                                      area_unit = "ha",
                                      unit_multiplier = KG_TO_TG)

summary_N2O_line <- as.list(rep("-", length(summary_col_names)))
names(summary_N2O_line) <- summary_col_names
summary_N2O_line$Dataset <- "IPCC AR5"
summary_N2O_line$Quantity <- "Soil N~2~0 Emissions"
summary_N2O_line$Unit <- "Tg N y^-1^"
summary_N2O_line$Data <- 11 # uncertainty +/- 3 could be incorporated somehow
for(this_sim in all_simulation_Sources_list) {
  summary_N2O_line[[this_sim@name]] <- this_soil_N2O_df[which(this_soil_N2O_df$Source == this_sim@name), "N2O"]
}

names(summary_N2O_line) <- names(summary_table)
summary_table <- rbind(summary_table, summary_N2O_line)


if(nrow(summary_table) > 0) {
  colnames(summary_table) <- summary_col_names
  kable(summary_table) %>% kable_styling(full_width = TRUE)
}

# save the table in each model run directory
# loop through model runs to be processed
for(this_sim_Source in all_simulation_Sources_list) {
  saveRDS(summary_table, file.path(this_sim_Source@dir, paste0("summary_totals_", version_label, ".RData")))
}


```


## Model-data Agreement Metrics

``` {r Global metrics, echo=FALSE, out.width = '100%', out.height= '150%'}


if(nrow(metric_table) > 0) {
  # colnames(metric_table) <- metric_col_names
  
  # substitute "r2" for something prettier in the "Metric" column
  metric_table$Metric <- gsub(pattern = "r2", replacement = "R^2^", metric_table$Metric)
  
  # print the table
  kable(metric_table) %>% kable_styling(full_width = TRUE)
}

# save the table in each model run directory
# loop through model runs to be processed
for(this_sim_Source in all_simulation_Sources_list) {
  saveRDS(metric_table, file.path(this_sim_Source@dir, paste0("summary_metric_", version_label, ".RData")))
}


```


# Timing
Total run time:
``` {r time}

# report total run time
toc()

```