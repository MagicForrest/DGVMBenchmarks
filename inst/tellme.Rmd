---
title: "Tellme Benchmark Report for LPJ-GUESS"
author: "Matthew Forrest"
date: '`r strftime(Sys.time(), format = "%B %d, %Y")`'
output: 
  html_document:
    toc: true
params:
  new_directory:
    value: "/home/mforrest/GuessRuns/Tellus_dev/trunk10115crg+monthly"
  new_name:
    value: "New Run"
  old_directory:
    value: "/home/mforrest/GuessRuns/Tellus_dev/trunk10115crg+monthly"
  old_name:
    value: "Old Run"
  data_directory: 
    value: "/data/shared/Tellus"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      out.width = '100%',
                      fig.height = 7)
library(DGVMTools)
library(DGVMBenchmarks)
library(terra)
library(viridis)
library(ggplot2)
library(mapproj)
library(pals)
library(knitr)
library(dplyr)

library(tictoc)

# conversion factors
KG_TO_PG <- 1/1e+12
KM2_TO_MegaM2 <- 1/1e+12

# start timer
tic()


```

# Settings

Below you can see the setting for this run of the benchmarking script.

```{r settings, echo = TRUE}

#### DEFINE LPJ-GUESS RUNS ####
# NOTE:
#  The paths defined in the "dir" argument only point to the overall benchmark directory.  
#  To actually access one of the benchmark runs (ie crop_global) you should copy these Source objects 
#  and manually append the benchmark directory name to the "dir".  See the GCP code block for an example.

# new
new_simulation_Source <- defineSource(name = params$new_name,
                                      dir = params$new_directory,
                                      format = GUESS)


# reference run
old_simulation_Source <- defineSource(name = params$old_name,
                                      dir = params$old_directory,
                                      format = GUESS)

# combine into a list for looping later
all_simulation_Sources_list <- list(old_simulation_Source, new_simulation_Source)

# quik read switch and version label (for making quick read files)
quick_read <- TRUE
version_label <- "tellus_v1.1" 

# do publication plots
doPublicationPlots <- FALSE

# switches for which benchmarks to do
do_GCP_NBP <- TRUE
do_Biomes <- TRUE
do_global_GPP <- TRUE
do_global_LAI <- TRUE
do_GFED4_BA <- TRUE
do_Pan_Biomass <- FALSE
do_Global_Biomass <- FALSE


# The summary table
summary_col_names <- c("Quantity", "Unit")
for(this_sim in all_simulation_Sources_list) {
  summary_col_names <- append(summary_col_names, this_sim@name)
}
summary_col_names <- append(summary_col_names, c("Data", "Dataset", "Dataset ref."))
summary_table <- data.frame(check.names = FALSE, stringsAsFactors = FALSE)


# Standard plot formatting arguments
num_cols <- 1
map_overlay <- "coastlines"
stats_lon <- -130
stats_lat <- -20


```

---



# Global Carbon Project Net Biome Poductivity

Potential intro text about GCP, links to online description of the data, what to look for in the benchmark, etc.


```{r gcp, fig.height=5}

if(do_GCP_NBP){
  
  ### Read the data and calculate the annual mean over the whole period
  GCP_full_Field <- read_GCP()
  GCP_full_Field_ymean  <- suppressWarnings(aggregateYears(GCP_full_Field, "mean"))
  
  
  # make a list of all Fields to be compared  (this will also include whatever model runs are available)
  all_NBP_Fields_list <- list("GCP" = GCP_full_Field)
  # and the vector of labels to eventual put on the plot
  all_NBP_labels_vector <- c(paste0("GCB residual: ", signif(GCP_full_Field_ymean@data[["NEE"]], 3), " TgC/year"))
  
  
  ### Read the LPJ-GUESS data
  
  # for now hard code the first and last years
  first_GCP_GUESS_year <- 1959
  last_GCP_GUESS_year <- 2015
  
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    this_benchmark_run_dir <- file.path(this_sim_Source@dir, "crop_global")
    if(file.exists(file.path(this_benchmark_run_dir, "cflux.out")) || file.exists(file.path(this_benchmark_run_dir, "cflux.out.gz"))) {
      
      # make local sources pointing to the crop_global directory
      this_crop_global_Source <- this_sim_Source
      this_crop_global_Source@dir <- this_benchmark_run_dir
      
      # read the data and process it into global sums
      this_simulation_NBP <- getField(source = this_crop_global_Source,
                                      "cflux",
                                      first.year = first_GCP_GUESS_year,
                                      last.year = last_GCP_GUESS_year,
                                      spatial.aggregate.method = "w.sum",
                                      spatial.extent.id = "Global",
                                      quick.read = quick_read,
                                      quick.read.file = paste("cflux", version_label, sep = "_") 
      )
      this_simulation_NBP <- layerOp(x = this_simulation_NBP, operator = "divc", layers = layers(this_simulation_NBP), new.layer = layers(this_simulation_NBP), constant = -1E12)
      
      # store the Field in the list of all Fields for plotting later
      all_NBP_Fields_list[[this_sim_Source@id]] <- this_simulation_NBP
      
      # calculate yearly means of whole period
      # supressWarnings is just to stops warnings that there is no spatial or temporal data in the resulting Field
      # (all averaged away to give a single number)
      this_simulation_NBP_ymean <- suppressWarnings(aggregateYears(this_simulation_NBP, "mean"))
      
      # make a text label for putting the yearly mean on th plot and aa it to the label vector of labels
      all_NBP_labels_vector <- append(all_NBP_labels_vector, paste0(this_simulation_NBP_ymean@source@name, 
                                                                    ": ", 
                                                                    signif(this_simulation_NBP_ymean@data[["NEE"]],3), 
                                                                    " PgC/year"))
    } 
    
  }
  
  
  # plot all together
  NBP_plot <- plotTemporal(all_NBP_Fields_list, 
                           col.by = "Source", 
                           layers = "NEE", 
                           title = "Global NBP", 
                           subtitle = NULL, 
                           y.label = "Global NBP (PgC/year)",
                           text.multiplier = 1.5, 
                           sizes = 1)
  
  # make a simple data.frame to put numbers on the plot, and then add it to the plot
  global.numbers.df <- data.frame(x= rep(as.Date(paste(first_GCP_GUESS_year), "%Y")), 
                                  y = c(6, 5, 4), 
                                  label = all_NBP_labels_vector)
  NBP_plot <-  NBP_plot + geom_text(data = global.numbers.df,  mapping = aes(x = x, y = y, label = label), size = 6, hjust = 0, col = "black")
  print(NBP_plot)
  
  
}

```
<a href="#top">Back to top</a>

---

# PNV Biomes

##  Dinerstein 2017 ecoregions (no model output classification available)

Any volunteers for performing such a classification?  If you do, Stefan will buy you a beer.

## Haxeltine and Prentice 1992 biomes, classification following Smith et al 2014.


```{r Global PNV biomes, fig.height = 9}

#### H&P Biomes ####
if(do_Biomes){
  
  # Define the benchmark
  this_benchmark <- list(
    description = "Global biomes",
    simulation = c("global", "tellus"),
    guess_var = "lai"
  )
  
  ### the benchmarking datasets for global biomass
  smith_biomes = list(
    first_year = 1960,
    last_year = 1990,
    dir = "biomes/HanP_PNV",
    file_name = "Smith2014.nc",
    id = "Smith2014",
    name = "Haxeltine and Prentice 1992 biomes",
    this_unit = "PgC"
  )
  this_dataset <- smith_biomes
  
  ### Lists for storing the field and totals
  ###  NOTE: This gets a special name cause it is used later
  Biome_Map_Fields_list <- list()
  
  #### READ DATASET ####
  full_file_path <- file.path(params$data_directory, this_dataset$dir, this_dataset$file_name)
  if(file.exists(full_file_path)) {
    
    suppressWarnings(
      Biome_Map_Fields_list[[this_dataset$name]] <- getField(source = defineSource(id = this_dataset$id,
                                                                                   name = this_dataset$name,
                                                                                   dir = file.path(params$data_directory, this_dataset$dir),
                                                                                   format = NetCDF),
                                                             quant = this_dataset$id,
                                                             first.year = this_dataset$first_year,
                                                             last.year = this_dataset$last_year,
                                                             year.aggregate.method = "mean",
                                                             quick.read = FALSE,
                                                             quick.read.file = paste(this_benchmark$guess_var, version_label, sep = "_"))
    )
    
    
  }
  else {
    message("Biomes dataset not found, benchmark will be skipped.")
    do_Global_biomass <- FALSE
  }
  
  #### DERIVE BIOMES FROM LPJ-GUESS DATA ####
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    got_simulation <- FALSE
    for(this_simulation in this_benchmark$simulation) {
      this_benchmark_run_dir <- file.path(this_sim_Source@dir, this_simulation)
      if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark$guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark$guess_var, ".out.gz")))) {
        got_simulation <- TRUE
        break
      }
    }
    if(got_simulation){
      
      # read the full data and
      temp_simulation_Source <- this_sim_Source
      temp_simulation_Source@dir <- this_benchmark_run_dir
      suppressWarnings(
        Biome_Map_Fields_list[[this_sim_Source@id]] <- getScheme(source = temp_simulation_Source,
                                                                 scheme = Smith2014BiomeScheme,
                                                                 first.year = this_dataset$first_year,
                                                                 last.year = this_dataset$last_year,
                                                                 year.aggregate.method = "mean",
                                                                 quick.read = quick_read,
                                                                 quick.read.file = paste(this_benchmark$guess_var,version_label, sep = "_"))
      )
      
    } # if file is present 
    else {
      message("Modelled biomass file not found, benchmark will be skipped.")
      do_Global_biomass <- FALSE
    }
    
  } # for each model run

  suppressWarnings(biome_plot <- plotSpatial(Biome_Map_Fields_list, 
                                             ncol = num_cols, 
                                             text.multiplier = 1.3, 
                                             map.overlay = map_overlay, 
                                             title = NULL))
  biome_plot <- biome_plot + theme(legend.position = "bottom",
                                   legend.text=element_text(size=rel(0.9)),
                                   legend.key.size = unit(0.5, "lines"))
  
  biome_plot <- biome_plot+ guides(fill = guide_legend(ncol = 2))
  suppressWarnings(plot(biome_plot))
  
  
  # such a nice solution, integrate into package....
  # library(rnaturalearth)
  # countryLines <- ne_coastline(returnclass = "sf")
  # biome_plot2 <- biome_plot+geom_sf(data=countryLines, linewidth = 0.1)
  # print(biome_plot2)
  
  
} # if do_Global_Biomass



```


<a href="#top">Back to top</a>

---


# GOSIF Gross Primary Productivity

Intro, data links, etc.

```{r GOSIF GPP data prep, echo=FALSE, out.width = '100%'}

if(do_global_GPP){
  
  # Currently only got one GPP dataset, but code as a list of data source for future flexibility
  GPP_data_Fields <- list()
  
  #### GOSIF GPP SETTINGS AND DATA ####
  
  GOSIF_GPP_monthly_dir <- "monthly_gpp/GOSIFGPP"
  GOSIF_GPP_monthly_file.name <- "GOSIF_GPP.txt"
  GOSIF_GPP_Source <- defineSource(id = "GOSIF_GPP",
                                   name = "GOSIF GPP",
                                   dir = file.path(params$data_directory, GOSIF_GPP_monthly_dir),
                                   format = GUESS)
  
  full_file_path <- file.path(GOSIF_GPP_Source@dir, GOSIF_GPP_monthly_file.name)
  if(!file.exists(full_file_path)) {
    print("GOSIF GPP data not available.")
  } else {
    GPP_data_Fields[[GOSIF_GPP_Source@name]] <- getField(source = GOSIF_GPP_Source,
                                                         quant = "mgpp",
                                                         file.name = GOSIF_GPP_monthly_file.name)
  }
  
  
  #### PREPARE GPP BENCHMARK SETTINGS AND DATA ####
  
  if(length(GPP_data_Fields) == 0) {
    do_global_GPP <- FALSE
    print("Skipping GPP benchmark because no datasets available.")
  }
  else {
    
    # find overlapping years (general case if multiple datasets)
    first.year = last.year = NA
    for(this_Field in GPP_data_Fields) {
      first.year <- min(c(this_Field@first.year, first.year), na.rm = TRUE)
      last.year <- max(c(this_Field@last.year, last.year), na.rm = TRUE)
    }
    
    this_benchmark <- new("Benchmark",
                          id = "Global_GPP",
                          name = "Global GPP",
                          description = "Global GPP",
                          simulation = "tellus",
                          guess_var = "mgpp",
                          guess_layers = "mgpp",
                          unit = "kg m^-2^ y^-1^",
                          agg.unit = "PgC y^-1^",
                          datasets = GPP_data_Fields,
                          first.year = first.year,
                          last.year = last.year,
                          metrics = c("NME", "RMSE"))
    
    
    summary_table_lines <- makeSummaryLine(this_benchmark, summary_col_names)
    
    
    
    ### Lists for storing the appropriate Fields and summary numbers
    all_GPP_Maps <- list()
    all_GPP_Trends <- list()
    all_GPP_Seasonal <- list()
    all_GPP_totals <- list()
    
    # Process the datasets according to the benchmark parameters above
    # this code will likely need to be adjusted depending on the details of variables, units, datasets etc
    for(this_data_Field in this_benchmark@datasets) {
      
      # crop the data to the comment benchmark year
      this_data_Field <- selectYears(this_data_Field, first = this_benchmark@first.year, last = this_benchmark@last.year)
      
      # delete values with -9999 and covert to kg
      this_data_Field@data <- this_data_Field@data[mgpp != -9999.0,]
      
      # Calculate the slope (still in grams)
      all_GPP_Trends[[this_data_Field@source@name]] <- calcLinearTrend(this_data_Field)
      
      # go from g to kg for spatial maps
      this_data_Field <- layerOp(this_data_Field, operator = "divc", constant = 1000, layers = "mgpp", new.layer = "mgpp")
      
      # make the annual map for comparison (leave only spatial)
      all_GPP_Maps[[this_data_Field@source@name]] <- aggregateYears(aggregateSubannual(this_data_Field, method = "sum", target = "Year"), method = "mean")
      
      # make the seasonal cycle for comparison (leave months andspatial)
      all_GPP_Seasonal[[this_data_Field@source@name]] <- aggregateYears(this_data_Field, method = "mean")
      
      # make and save the mean annual global GPP
      # TODO, make this more flexible for multiple datasets
      data_GPP_PgC <- areaWeightedTotal(all_GPP_Maps[[this_data_Field@source@name]])@data*KG_TO_PG
      all_GPP_totals[[this_data_Field@source@name]] <- data_GPP_PgC
      summary_table_lines$Data <- signif(as.numeric(data_GPP_PgC),4)
      
    }
    
    #### READ LPJ-GUESS DATA ####
    
    # loop through model runs to be processed
    for(this_sim_Source in all_simulation_Sources_list) {
      
      # check if file is present (if not don't include this run)
      this_benchmark_run_dir <- file.path(this_sim_Source@dir,this_benchmark@simulation)
      if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark@guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark@guess_var, ".out.gz")))) {
        
        # make local sources pointing to the crop_global directory
        this_crop_global_Source <- this_sim_Source
        this_crop_global_Source@dir <- this_benchmark_run_dir
        
        # read the full data and
        suppressWarnings(
          this_simulation_GPP <- getField(source = this_crop_global_Source,
                                          this_benchmark@guess_var,
                                          first.year = this_benchmark@first.year,
                                          last.year = this_benchmark@last.year,
                                          quick.read = quick_read,
                                          quick.read.file = paste(this_benchmark@guess_var, version_label, sep = "_"))
        )
        
        ### take sum of month and average of years and store for later use - very easy ###
        all_GPP_Maps[[this_sim_Source@name]] <- aggregateYears(aggregateSubannual(this_simulation_GPP, target = "Year", method = "sum"),  "mean")
        
        ### take yearly average and store for later use - very easy ###
        all_GPP_Seasonal[[this_sim_Source@name]] <- aggregateYears(this_simulation_GPP, "mean")
        
        ### calculate and store the linear trend and p-value for every gridcell (also change unit to gC/m^-2/month^-2)
        this_GPP_Trend <- calcLinearTrend(this_simulation_GPP)
        this_GPP_Trend <- layerOp( this_GPP_Trend, operator = "mulc", constant = 1000, layers = "Trend", new.layer = "Trend")
        this_GPP_Trend <- layerOp( this_GPP_Trend, operator = "mulc", constant = 1000, layers = "Significant_Trend", new.layer = "Significant_Trend")
        all_GPP_Trends[[this_sim_Source@name]] <- this_GPP_Trend
        
        # calculate and save the global total
        this_GPP_PgC <- areaWeightedTotal(all_GPP_Maps[[this_sim_Source@name]])@data*KG_TO_PG
        all_GPP_totals[[this_sim_Source@name]] <- this_GPP_PgC
        summary_table_lines[[this_sim_Source@name]] <- signif(as.numeric(this_GPP_PgC),4)
        
        # remove to save memory
        rm(this_simulation_GPP)
        
      } # if file is present 
      else {
        do_global_GPP <- FALSE
      }
      
    } # for each model run
    
    
    # do all spatial comparisons and store them in a big list'o'lists to be plotted in the next code chunks
    all_GPP_comparisons <- fullSpatialComparison(this_benchmark, all_GPP_Maps, all_GPP_Trends, all_GPP_Seasonal, params$new_name, params$old_name)
    
    # save the summary table line 
    # TODO - add the data references
    summary_table <- rbind(summary_table, summary_table_lines)
    
    
  } # if data are available
  
} # if do_global_GPP
```

## Spatial patterns {.tabset}

### Absolute values
```{r}
if(do_global_GPP){  
  # plot all absolute values together
  GPP_abs_values_plot <- plotSpatial(all_GPP_Maps, 
                                     ncol = num_cols, 
                                     legend.title = expression(kgC~m^{"-2"}~year^{"-1"}),
                                     map.overlay = map_overlay, 
                                     title = "Absolute GPP values",
                                     subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # add the total GPP to the plots
  total_label_df <- data.frame()
  for(this_panel in names(all_GPP_totals))  total_label_df <- rbind(total_label_df,
                                                                    list(label = paste(round(all_GPP_totals[[this_panel]], 1), "PgC/year"), 
                                                                         Facet = this_panel, 
                                                                         x = stats_lon, y = stats_lat),
                                                                    stringsAsFactors = FALSE)
  total_label_df$Facet <- factor(total_label_df$Facet, levels = names(all_GPP_totals))
  GPP_abs_values_plot  <- GPP_abs_values_plot  + geom_text(data = total_label_df,  mapping = aes(x = x, y = y, label = label), size = 2.5)
  suppressWarnings(print(GPP_abs_values_plot))
}
```

### Differences

```{r}
if(do_global_GPP){  
  
  GPP_diff_values_plot <- plotSpatialComparison(all_GPP_comparisons[["Values"]], 
                                                ncol = num_cols, 
                                                legend.title = expression(Delta~kgC~m^{"-2"}~year^{"-1"}),
                                                map.overlay = map_overlay, 
                                                title = "GPP biases", 
                                                facet.order = names(all_GPP_comparisons[["Values"]]),
                                                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # extract metric scores and add to the panels
  lat_offset = 0
  for(this_metric in this_benchmark@metrics) {
    metric_label_df <- data.frame()
    for(comparison_name  in names(all_GPP_comparisons[["Values"]])) {
      metric_label_df <- rbind(metric_label_df,
                               list(label = paste(this_metric, "=", round(all_GPP_comparisons[["Values"]][[comparison_name]]@stats[[this_metric]], 2)), 
                                    Facet = comparison_name, 
                                    x = stats_lon, y = stats_lat - lat_offset),
                               stringsAsFactors = FALSE)  
    }
    metric_label_df$Facet <- factor(metric_label_df$Facet, levels = names(all_GPP_comparisons[["Values"]]))
    GPP_diff_values_plot  <- GPP_diff_values_plot  + geom_text(data = metric_label_df,  mapping = aes(x = x, y = y, label = label), size = 3)
    lat_offset <- lat_offset + 10  
  }
  
  suppressWarnings(print(GPP_diff_values_plot))
  
  GPP_diff_values_plot_table  <- plotSpatialComparison(all_GPP_comparisons[["Values"]], 
                                                       ncol = num_cols, 
                                                       legend.title = expression(Delta~kgC~m^{"-2"}~year^{"-1"}),
                                                       map.overlay = map_overlay, 
                                                       title = "GPP biases", 
                                                       subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"),
                                                       plot = FALSE)
  
}
```



## Temporal trends {.tabset}

### Trend value
```{r}
if(do_global_GPP) {
  suppressWarnings( print(
    plotSpatial(all_GPP_Trends, 
                layers = "Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.2,0.2),
                drop.cuts = FALSE,
                title = "Trend in GPP", 
                legend.title = expression(gC~m^{"-2"}~month^{"-2"}),
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Trend significance
```{r}
if(do_global_GPP) {
  suppressWarnings(print(
    plotSpatial(all_GPP_Trends, 
                layers = "p.value", 
                ncol = num_cols, 
                cols = viridis::turbo(6), 
                cuts = c(0, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0),
                drop.cuts = FALSE,
                title = "Significance in GPP Trends",
                legend.title =  "p value",
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}

```

### Trend Differences
```{r}
if(do_global_GPP) {
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Trend"]], 
                          ncol = num_cols, 
                          drop.cuts = NULL,
                          title = "Difference Trend in GPP", 
                          legend.title =  expression(Delta~gC~m^{"-2"}~month^{"-2"}),
                          map.overlay = map_overlay,                
                          subtitle =paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Significant Trends
```{r}
if(do_global_GPP) {
  suppressWarnings( print(
    plotSpatial(all_GPP_Trends, 
                layers = "Significant_Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.2,0.2),
                drop.cuts = FALSE,
                title = "Significant Trend in GPP (p-value < 0.05)", 
                legend.title = expression(gC~m^{"-2"}~month^{"-2"}),
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```



## Seasonal analysis {.tabset}
Definition of seasonal concentration and phase follow Kelley *et al.* 2013.  **Seasonal concentration** equals one if the variable is concentrated all in one month, and is zero if it is spread even across all months.  The **seasonal phase** is a measure of the peak of the season - it is not strictly the maximum monthly, but rather the average of all months when considering months as an angle in the complex plane.  

### Seasonal phase
```{r}
if(do_global_GPP) {
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          type = "values",
                          cuts = 0:12, 
                          override.cols = pals::ocean.phase(12),
                          ncol = num_cols,
                          map.overlay = map_overlay,   
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Phase differences
```{r}
if(do_global_GPP){
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          cuts = seq(-6,6), 
                          symmetric.scale = FALSE,
                          ncol = num_cols,
                          map.overlay = map_overlay,    
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


### Seasonal concentration
```{r}
if(do_global_GPP) {
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Seasonal"]], 
                          type = "values",
                          ncol = num_cols,
                          map.overlay = map_overlay,            
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Concentration differences
```{r}
if(do_global_GPP) {
  suppressWarnings(print(
    plotSpatialComparison(all_GPP_comparisons[["Seasonal"]], 
                          ncol = num_cols,
                          map.overlay = map_overlay,           
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


<a href="#top">Back to top</a>

---

# MODIS Leaf Area Index


```{r LAI data prep, echo=FALSE, out.width = '100%'}

if(do_global_LAI){
  
  # Currently only got one LAI dataset, but code as a list of data source for future flexibility
  LAI_data_Fields <- list()
  
  #### MODIS LAI SETTINGS AND DATA ####
  
  MODIS_LAI_monthly_dir <- "monthly_lai/MODIS"
  MODIS_LAI_monthly_file.name <- "MODIS_LAI.txt"
  MODIS_LAI_Source <- defineSource(id = "MODIS_LAI",
                                   name = "MODIS LAI",
                                   dir = file.path(params$data_directory, MODIS_LAI_monthly_dir),
                                   format = GUESS)
  
  full_file_path <- file.path(MODIS_LAI_Source@dir, MODIS_LAI_monthly_file.name)
  if(!file.exists(full_file_path)) {
    print("MODIS LAI data not available.")
  } else {
    LAI_data_Fields[[MODIS_LAI_Source@name]] <- getField(source = MODIS_LAI_Source,
                                                         quant = "mlai",
                                                         file.name = MODIS_LAI_monthly_file.name)
  }
  
  
  #### PREPARE LAI BENCHMARK SETTINGS AND DATA ####
  
  if(length(LAI_data_Fields) == 0) {
    do_global_LAI <- FALSE
    print("Skipping LAI benchmark because no datasets available.")
  }
  else {
    
    # find overlapping years (general case if multiple datasets)
    first.year = last.year = NA
    for(this_Field in LAI_data_Fields) {
      first.year <- min(c(this_Field@first.year, first.year), na.rm = TRUE)
      last.year <- max(c(this_Field@last.year, last.year), na.rm = TRUE)
    }
    
    this_benchmark <- new("Benchmark",
                          id = "Global_LAI",
                          name = "Global LAI",
                          description = "Global leaf area",
                          simulation = "tellus",
                          guess_var = "mlai",
                          guess_layers = "mlai",
                          unit = "m^2^ m^-2^",
                          agg.unit = "Mm^2^",
                          datasets = LAI_data_Fields,
                          first.year = first.year,
                          last.year = last.year,
                          metrics = c("NME", "RMSE"))
    
    
    makeSummaryLine <- function(benchmark, col_names) {
      summary_table_lines <- as.list(rep("-", length(col_names)))
      names(summary_table_lines) <- col_names
      for(this_dataset in benchmark@datasets) {
        if(summary_table_lines$Dataset == "-") summary_table_lines$Dataset <- this_dataset@source@name
        else summary_table_lines$Dataset <- paste0(summary_table_lines$Dataset, ", ", this_dataset@source@name) 
      }
      summary_table_lines$Quantity <- benchmark@description
      summary_table_lines$Unit <- benchmark@agg.unit
      return(summary_table_lines)
    }
    summary_table_lines <- makeSummaryLine(this_benchmark, summary_col_names)
    
    
    
    ### Lists for storing the appropriate Fields and summary numbers
    all_LAI_Maps <- list()
    all_LAI_Trends <- list()
    all_LAI_Seasonal <- list()
    all_LAI_totals <- list()
    
    # Process the datasets according to the benchmark parameters above
    # this code will likely need to be adjusted depending on the details of variables, units, datasets etc
    for(this_data_Field in this_benchmark@datasets) {
      
      # crop the data to the comment benchmark year
      this_data_Field <- selectYears(this_data_Field, first = this_benchmark@first.year, last = this_benchmark@last.year)
      
      # delete values with -9999 and covert to kg
      this_data_Field@data <- this_data_Field@data[mlai != -9999.0,]
      
      # Calculate the slope (still in grams)
      all_LAI_Trends[[this_data_Field@source@name]] <- calcLinearTrend(this_data_Field)
      
      # make the annual map for comparison (leave only spatial)
      all_LAI_Maps[[this_data_Field@source@name]] <- aggregateYears(aggregateSubannual(this_data_Field, method = "max", target = "Year"), method = "mean")
      
      # make the seasonal cycle for comparison (leave months andspatial)
      all_LAI_Seasonal[[this_data_Field@source@name]] <- aggregateYears(this_data_Field, method = "mean")
      
      # make and save the mean annual global LAI
      # TODO, make this more flexible for multiple datasets
      data_LAI_PgC <- areaWeightedTotal(all_LAI_Maps[[this_data_Field@source@name]])@data * KM2_TO_MegaM2
      all_LAI_totals[[this_data_Field@source@name]] <- data_LAI_PgC
      summary_table_lines$Data <- signif(as.numeric(data_LAI_PgC),4)
      
    }
    
    #### READ LPJ-GUESS DATA ####
    
    # loop through model runs to be processed
    for(this_sim_Source in all_simulation_Sources_list) {
      
      # check if file is present (if not don't include this run)
      this_benchmark_run_dir <- file.path(this_sim_Source@dir,this_benchmark@simulation)
      if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark@guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark@guess_var, ".out.gz")))) {
        
        # make local sources pointing to the crop_global directory
        this_crop_global_Source <- this_sim_Source
        this_crop_global_Source@dir <- this_benchmark_run_dir
        
        # read the full data and
        suppressWarnings(
          this_simulation_LAI <- getField(source = this_crop_global_Source,
                                          this_benchmark@guess_var,
                                          first.year = this_benchmark@first.year,
                                          last.year = this_benchmark@last.year,
                                          quick.read = quick_read,
                                          quick.read.file = paste(this_benchmark@guess_var, version_label, sep = "_"))
        )
        
        ### take sum of month and average of years and store for later use - very easy ###
        all_LAI_Maps[[this_sim_Source@name]] <- aggregateYears(aggregateSubannual(this_simulation_LAI, target = "Year", method = "max"),  "mean")
        
        ### take yearly average and store for later use - very easy ###
        all_LAI_Seasonal[[this_sim_Source@name]] <- aggregateYears(this_simulation_LAI, "mean")
        
        ### calculate and store the linear trend and p-value for every gridcell 
        all_LAI_Trends[[this_sim_Source@name]] <- calcLinearTrend(this_simulation_LAI)
        
        # calculate and save the global total
        this_LAI_PgC <- areaWeightedTotal(all_LAI_Maps[[this_sim_Source@name]])@data * KM2_TO_MegaM2
        all_LAI_totals[[this_sim_Source@name]] <- this_LAI_PgC
        summary_table_lines[[this_sim_Source@name]] <- signif(as.numeric(this_LAI_PgC),4)
        
        # remove to save memory
        rm(this_simulation_LAI)
        
      } # if file is present 
      else {
        do_global_LAI <- FALSE
      }
      
    } # for each model run
    
    
    # do all spatial comparisons and store them in a big list'o'lists to be plotted in the next code chunks
    all_LAI_comparisons <- fullSpatialComparison(this_benchmark, all_LAI_Maps, all_LAI_Trends, all_LAI_Seasonal, params$new_name, params$old_name)
    
    # save the summary table line 
    # TODO - add the data references
    names(summary_table_lines) <- names(summary_table)
    summary_table <- rbind(summary_table, summary_table_lines)
    
    
  } # if data are available
  
} # if do_global_LAI
```



## Spatial patterns {.tabset}

### Absolute values
```{r}
if(do_global_LAI){  
  # plot all absolute values together
  LAI_abs_values_plot <- plotSpatial(all_LAI_Maps, 
                                     ncol = num_cols, 
                                     legend.title = expression(m^{"2"}~m^{"-2"}),
                                     map.overlay = map_overlay,  
                                     title = "Absolute LAI values",
                                     limits = c(0,8),
                                     subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # add the total LAI to the plots
  total_label_df <- data.frame()
  for(this_panel in names(all_LAI_totals))  total_label_df <- rbind(total_label_df,
                                                                    list(label = paste(round(all_LAI_totals[[this_panel]], 1), "M m^2"), 
                                                                         Facet = this_panel, 
                                                                         x = stats_lon, y = stats_lat),
                                                                    stringsAsFactors = FALSE)
  total_label_df$Facet <- factor(total_label_df$Facet, levels = names(all_LAI_totals))
  LAI_abs_values_plot  <- LAI_abs_values_plot  + geom_text(data = total_label_df,  mapping = aes(x = x, y = y, label = label), size = 2.5)
  suppressWarnings(print(LAI_abs_values_plot))
}
```

### Differences

```{r}
if(do_global_LAI){  
  LAI_diff_values_plot <- plotSpatialComparison(all_LAI_comparisons[["Values"]], 
                                                ncol = num_cols, 
                                                legend.title = expression(Delta~m^{"2"}~m^{"-2"}),
                                                map.overlay = map_overlay,             
                                                title = "LAI biases", 
                                                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))
  
  # extract metric scores and add to the panels
  lat_offset = 0
  for(this_metric in this_benchmark@metrics) {
    metric_label_df <- data.frame()
    for(comparison_name  in names(all_LAI_comparisons[["Values"]])) {
      metric_label_df <- rbind(metric_label_df,
                               list(label = paste(this_metric, "=", round(all_LAI_comparisons[["Values"]][[comparison_name]]@stats[[this_metric]], 2)), 
                                    Facet = comparison_name, 
                                    x = stats_lon, y = stats_lat - lat_offset),
                               stringsAsFactors = FALSE)  
    }
    metric_label_df$Facet <- factor( metric_label_df$Facet, names(all_LAI_comparisons[["Values"]]))
    
    LAI_diff_values_plot  <- LAI_diff_values_plot  + geom_text(data = metric_label_df,  mapping = aes(x = x, y = y, label = label), size = 3)
    lat_offset <- lat_offset + 10  
  }
  
  suppressWarnings(print(LAI_diff_values_plot))
}
```



## Temporal trends {.tabset}

### Trend value
```{r}
if(do_global_LAI) {
  suppressWarnings( print(
    plotSpatial(all_LAI_Trends, 
                layers = "Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.01,0.01),
                drop.cuts = FALSE,
                title = "Trend in LAI", 
                legend.title = expression(m^{"2"}~m^{"-2"}~month^{"-2"}),
                map.overlay = map_overlay,                  
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Trend significance
```{r}
if(do_global_LAI) {
  suppressWarnings(print(
    plotSpatial(all_LAI_Trends, 
                layers = "p.value", 
                ncol = num_cols, 
                cols = viridis::turbo(6), 
                cuts = c(0, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0),
                drop.cuts = FALSE,
                title = "Significance in LAI Trends",
                legend.title =  "p value",
                map.overlay = map_overlay,                   
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}

```

### Trend Differences
```{r}
if(do_global_LAI) {
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Trend"]], 
                          ncol = num_cols, 
                          drop.cuts = NULL,
                          title = "Difference Trend in LAI", 
                          legend.title =  expression(m^{"2"}~m^{"-2"}~month^{"-2"}),
                          map.overlay = map_overlay,          
                          subtitle =paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
  
}
```


### Significant Trends
```{r}
if(do_global_LAI) {
  suppressWarnings( print(
    plotSpatial(all_LAI_Trends, 
                layers = "Significant_Trend", 
                ncol = num_cols, 
                cols = rev(RColorBrewer::brewer.pal(11, "RdBu")), 
                limits = c(-0.01,0.01),
                drop.cuts = FALSE,
                title = "Significant Trend in GPP (p-value < 0.05)", 
                legend.title = expression(expression(m^{"2"}~m^{"-2"}~month^{"-2"})),
                map.overlay = map_overlay, 
                subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


## Seasonal analysis {.tabset}
Definition of seasonal concentration and phase follow Kelley *et al.* 2013.  **Seasonal concentration** equals one if the variable is concentrated all in one month, and is zero if it is spread even across all months.  The **seasonal phase** is a measure of the peak of the season - it is not strictly the maximum monthly, but rather the average of all months when considering months as an angle in the complex plane.  

### Seasonal phase
```{r}
if(do_global_LAI) {
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          type = "values",
                          cuts = 0:12, 
                          override.cols = pals::ocean.phase(12),
                          ncol = num_cols,
                          map.overlay = map_overlay,                   
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Phase differences
```{r}
if(do_global_LAI){
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Seasonal"]], 
                          do.phase = TRUE,
                          cuts = seq(-6,6), 
                          symmetric.scale = FALSE,
                          ncol = num_cols,
                          map.overlay = map_overlay,                              
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


### Seasonal concentration
```{r}
if(do_global_LAI) {
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Seasonal"]], 
                          type = "values",
                          ncol = num_cols,
                          map.overlay = map_overlay,                          
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```

### Concentration differences
```{r}
if(do_global_LAI) {
  suppressWarnings(print(
    plotSpatialComparison(all_LAI_comparisons[["Seasonal"]], 
                          ncol = num_cols,
                          map.overlay = map_overlay,                       
                          subtitle = paste(this_benchmark@first.year, this_benchmark@last.year, sep = "-"))))
}
```


<a href="#top">Back to top</a>

---


# GFED4 burnt area



```{r GFED4 BA data prep, echo=FALSE, out.width = '100%'}


#### GFED4 Burnt Area Data Prep ####

if(do_GFED4_BA){
  
  ### Here we read the model and data for both the spatial and trend analyses (which are actually done in the next code blocks)
  
  ### some parameters and settings
  guess_var <- "mburned_area"
  first_year_GFED4 <- 2000
  last_year_GFED4 <- 2016
  this_data_dir <- "annual_ba/GFED4.0"
  this_data_file_name <- "GFED4.0_BA_2000-2016.nc"
  dataset_id <- "GFED4.0"
  dataset_name <- "GFED4.0"
  this_unit <- "Mha"
  benchmark_description <- "Global burnt area"
  
  
  summary_table_lines <- as.list(rep("-", length(summary_col_names)))
  names(summary_table_lines) <- summary_col_names
  summary_table_lines$Dataset <- dataset_name
  summary_table_lines$Quantity <- benchmark_description
  summary_table_lines$Unit <- this_unit
  
  
  ### Lists for storing the field and totals
  all_Map_Fields_list <- list()
  all_Trend_Fields_list <- list()
  all_Seasonal_Fields_list <- list()
  all_Totals_vec <- list()
  
  
  #### READ DATA ####
  full_file_path <- file.path(params$data_directory, this_data_dir, this_data_file_name)
  if(file.exists(full_file_path)) {
    
    # Read th data via a GUESS formatted Source
    data_Source <- defineSource(id = dataset_id,
                                name = dataset_name,
                                dir = file.path(params$data_directory, this_data_dir),
                                format = NetCDF)
    this_data_Field <- getField(source = data_Source,
                                quant = guess_var,
                                file.name = this_data_file_name)
    
    # calculate global total BA and put into a data.frame for the labels
    suppressWarnings(all_Totals_vec[[data_Source@name]] <- aggregateSpatial(selectLayers(this_data_Field, guess_var), method = "sum")@data/1e+6)
    summary_table_lines$Data <- signif(as.numeric(all_Totals_vec[[data_Source@name]]),4)
    
    
    # go from ha for fraction burnt area
    this_data_Field <- addArea(this_data_Field, "ha")
    this_data_Field <- layerOp(this_data_Field, "/", c(guess_var, "Area"), guess_var)
    this_data_Field <- layerOp(this_data_Field, NULL, "Area")
    this_data_Field@quant@units <- "1"
    
    # already aggregated to spatial map, so just save
    all_Map_Fields_list[[dataset_name]] <- this_data_Field
    
  }
  
  #### READ LPJ-GUESS BURNT AREA DATA ####
  
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    this_benchmark_run_dir <- file.path(this_sim_Source@dir, "crop_global")
    if(file.exists(file.path(this_benchmark_run_dir, paste0(guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(guess_var, ".out.gz")))) {
      
      # make local sources pointing to the crop_global directory
      this_crop_global_Source <- this_sim_Source
      this_crop_global_Source@dir <- this_benchmark_run_dir
      
      # read the full data and
      suppressWarnings(
        this_simulation_Field <- getField(source = this_crop_global_Source,
                                          guess_var,
                                          first.year = first_year_GFED4,
                                          last.year = last_year_GFED4,
                                          quick.read = quick_read,
                                          quick.read.file = paste(guess_var, version_label, sep = "_"))
      )
      
      ### take sum of month and average of years and store for later use - very easy ###
      all_Map_Fields_list[[this_sim_Source@id]] <- aggregateYears(aggregateSubannual(this_simulation_Field, target = "Year", method = "max"),  "mean")
      
      # also calculate global total BA and put into a data.frame for the labels
      temp_fld <- addArea(all_Map_Fields_list[[this_sim_Source@id]], "ha")
      temp_fld <- layerOp(temp_fld, "*", c(guess_var, "Area"), "Area_summed")
      suppressWarnings(all_Totals_vec[[this_sim_Source@name]] <- aggregateSpatial(selectLayers(temp_fld, "Area_summed"), method = "sum")@data/1e+6)
      rm(temp_fld)
      summary_table_lines[[this_sim_Source@name]] <- signif(as.numeric(all_Totals_vec[[this_sim_Source@name]]),4)
      
      #### COMMENTED OUT BECAUSE WE DONT HAVE MONTHLY DATA - but we might
      
      ### take yearly average and store for later use - very easy ###
      #all_Fields_list[[this_sim_Source@id]] <- aggregateYears(this_simulation_Field, "mean")
      
      ### calculate the linear trend and p-value for every gridcell and store for later use ###     
      #this_Trend <- calcLinearTrend(this_simulation_LAI)
      
      # store the Field in the list of all Fields for plotting later
      #all_Trend_Fields_list[[this_sim_Source@id]] <- this_Trend
      
      # remove to save memory
      rm(this_simulation_Field)
      
    } # if file is present 
    
  } # for each model run
  
  
  #### SPECIAL CASE FOR GFED4 - extract only the modelled gridcells and set the quantity to match the data ####
  modelled_gridcells <- getDimInfo(all_Map_Fields_list[["New_Run"]], info = "full")
  all_Map_Fields_list[[dataset_name]] <- selectGridcells(all_Map_Fields_list[[dataset_name]], gridcells = modelled_gridcells, "Full")
  all_Map_Fields_list[[dataset_name]]@quant <- all_Map_Fields_list[["New_Run"]]@quant
  
  
  
  # complete and  save the summary table line 
  # TODO - add the data references
  names(summary_table_lines) <- names(summary_table)
  summary_table <- rbind(summary_table, summary_table_lines)
  
} # if do_GFED4



```



```{r GFED4 BA map, echo=FALSE, out.width = '100%', out.height= '150%'}

if(do_GFED4_BA){
  
  ba.cuts <- c(0,0.002,0.005,0.01,0.02,0.05,0.10,0.2,0.50,1.0)
  ba.cols <- viridis::turbo(length(ba.cuts)-1)
  
  # Do spatial comparisons for each model run and calculated global GPP
  spatial_comparisons_list <- list()
  nme_scores_list <- list()
  
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # make comparison 
    # message(paste("Comparison stats for run", this_sim_Source@name, "GPP values vs. GOSIF GPP values"))
    suppressWarnings(
      spatial_comparisons_list[[this_sim_Source@id]] <- compareLayers(field1 = all_Map_Fields_list[[this_sim_Source@id]],
                                                                      field2 = all_Map_Fields_list[[data_Source@name]],
                                                                      layers1 =  guess_var,
                                                                      layers2 =  guess_var, 
                                                                      show.stats = FALSE)
    )
    
    # store the NME 
    nme_scores_list[[this_sim_Source@name]] <- spatial_comparisons_list[[this_sim_Source@id]]@stats$NME
    
  }
  
  
  # plot all slope values together
  abs_values_plot <- plotSpatial(all_Map_Fields_list, 
                                 ncol = num_cols, 
                                 legend.title = "BA Frac.",
                                 map.overlay = map_overlay,                                 
                                 cuts = ba.cuts,
                                 cols = ba.cols,
                                 title = NULL,
                                 subtitle = NULL)
  
  # add the total GPP to the plots
  total_label_df <- data.frame()
  for(this_panel  in names(all_Totals_vec))  total_label_df <- rbind(total_label_df,
                                                                     list(label = paste(round(all_Totals_vec[[this_panel]], 1), "Mha/year"), 
                                                                          Facet = this_panel, 
                                                                          x = -130, 
                                                                          y = -40),
                                                                     stringsAsFactors = FALSE)
  abs_values_plot  <- abs_values_plot  + geom_text(data = total_label_df,  mapping = aes(x = x, y = y, label = label), size = 2.5)
  
  
  # suppress warnings about uneven horizontal intervals
  suppressWarnings(print(abs_values_plot))
  
  # also make the difference plots
  diff_values_plot <- plotSpatialComparison(spatial_comparisons_list, 
                                            ncol = num_cols, 
                                            legend.title = expression(Delta ~"BA frac"),
                                            map.overlay = map_overlay,                                    
                                            title = "Burnt area biases", 
                                            subtitle = paste(first_year_GFED4, last_year_GFED4, sep = "-") )
  # add statistical metrics to the plots
  metric_label_df <- data.frame()
  for(this_panel  in names(nme_scores_list))  metric_label_df <- rbind(metric_label_df,
                                                                       list(label = paste("NME =", round(nme_scores_list[[this_panel]], 2)), 
                                                                            Facet = paste(this_panel, "-", data_Source@name), 
                                                                            x = -130, 
                                                                            y = -40),
                                                                       stringsAsFactors = FALSE)
  diff_values_plot  <- diff_values_plot  + geom_text(data = metric_label_df,  mapping = aes(x = x, y = y, label = label), size = 3)
  
  # suppress warnings about uneven horizontal intervals
  suppressWarnings(print(diff_values_plot))
  
}

```


<a href="#top">Back to top</a>

---


## Pan forest biomass



```{r Pan biomass data prep, echo=FALSE, out.width = '100%'}


#### Pan Biomass Data Prep ####

if(do_Pan_Biomass){
  
  ### Here we read the model and data for both the spatial and trend analyses (which are actually done in the next code blocks)
  
  ### some parameters and settings
  guess_var <- "cpool_natural"
  
  dataset_first_year <- 2007
  dataset_last_year <- 2007
  this_data_dir <- "Biomass"
  this_data_file_name <-  "pan_regional_data_reformatted.txt"
  dataset_id <- "GFED4.0"
  dataset_name <- "GFED4.0"
  this_unit <- "Mha"
  benchmark_description <- "Global burnt area"
  
  
  
  
  #### READ PAN REGIONAL BIOMASS DATA ####
  
  full_file_path <- file.path( system.file("extdata", "Biomass", package = "DGVMBenchmarks"), this_data_file_name) 
  
  if(file.exists(full_file_path)) {
    
    # read data, make global and total sums, and reformat 
    fread(full_file_path, quote = "") %>% 
      mutate(Global = Russia+Canada+N_Europe+USA+Europe+China+Japan+S_Korea+Australia+NZ+S_Asia+Africa+Americas) %>%
      melt.data.table(id.vars = c("Pool","Year")) %>% 
      dcast( ... ~ Pool) %>% 
      setnames(c("variable", "LIT", "SOI", "TLB"), c("Region", "LitterC", "SoilC", "VegC")) %>%
      mutate(Total = LitterC + SoilC + VegC + DWD) -> pan_dt
    
  }
  
  #### READ LPJ-GUESS LAI DATA ####
  
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    this_benchmark_run_dir <- file.path(this_sim_Source@dir, "crop_global")
    if(file.exists(file.path(this_benchmark_run_dir, paste0(guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(guess_var, ".out.gz")))) {
      
      # make local sources pointing to the crop_global directory
      this_crop_global_Source <- this_sim_Source
      this_crop_global_Source@dir <- this_benchmark_run_dir
      
      # read the full data and
      suppressWarnings(
        this_simulation_Field <- getField(source = this_crop_global_Source,
                                          guess_var,
                                          first.year = dataset_first_year, # TODO +/-3
                                          last.year = dataset_last_year,
                                          quick.read = quick_read,
                                          quick.read.file = paste(guess_var, version_label, sep = "_"))
      )
      
      # tide columns and make Total without harvest
      layerOp(this_simulation_Field, NULL, "HarvSlowC")
      layerOp(this_simulation_Field, "+", c("VegC", "LitterC", "SoilC"), "Total")
      
      
      # for Pan regions
      
      # extract regions
      # weighted sum across regions
      # add to table
      
      
      # 
      
      
      print(this_simulation_Field)
      
      
      stop()
      
      # remove to save memory
      rm(this_simulation_Field)
      
    } # if file is present 
    
    # combine tables
    
    # print table
    
  } # for each model run
  
  
  
} # if do_GFED4
```

<a href="#top">Back to top</a>

---



```{r Global biomass prep, echo=FALSE, out.width = '100%'}

#### Global Biomass Data Prep ####
if(do_Global_Biomass){
  
  # Define the benchmark
  this_benchmark <- list(
    description = "Global biomass",
    simulation = "tellus",
    guess_var = "cmass",
    guess_layers = c("Crop_sum", "Pasture_sum", "Natural_sum"),
    unit = "kg m^-2^",
    agg.unit = "PgC"
  )
  
  ### the benchmarking datasets for global biomass
  liu_biomass = list(
    first_year = 1993,
    last_year = 2012,
    this_data_dir = "annual_ba/GFED4.0",
    this_data_file_name = "GFED4.0_averageBA_2000-2016.nc",
    id = "liu",
    name = "Liu global biomass",
    this_unit = "PgC"
  )
  this_dataset <- liu_biomass
  
  summary_table_lines <- as.list(rep("-", length(summary_col_names)))
  names(summary_table_lines) <- summary_col_names
  summary_table_lines$Dataset <- this_benchmark$name
  summary_table_lines$Quantity <- this_benchmark$description
  summary_table_lines$Unit <- this_benchmark$agg.unit
  
  
  ### Lists for storing the field and totals
  all_Map_Fields_list <- list()
  all_Trend_Fields_list <- list()
  all_Seasonal_Fields_list <- list()
  all_Totals_vec <- list()
  
  
  #### READ DATASET ####
  full_file_path <- file.path(params$data_directory, this_data_dir, this_data_file_name)
  if(file.exists(full_file_path)) {
    
    # Read th data via a GUESS formatted Source
    data_Source <- defineSource(id = dataset_id,
                                name = dataset_name,
                                dir = file.path(params$data_directory, this_data_dir),
                                format = NetCDF)
    this_data_Field <- getField(source = data_Source,
                                quant = guess_var,
                                file.name = this_data_file_name)
    
    # calculate global total BA and put into a data.frame for the labels
    suppressWarnings(all_Totals_vec[[data_Source@name]] <- aggregateSpatial(selectLayers(this_data_Field, guess_var), method = "sum")@data/1e+6)
    summary_table_lines$Data <- signif(as.numeric(all_Totals_vec[[data_Source@name]]),4)
    
    
    # go from ha for fraction burnt area
    this_data_Field <- addArea(this_data_Field, "ha")
    this_data_Field <- layerOp(this_data_Field, "/", c(guess_var, "Area"), guess_var)
    this_data_Field <- layerOp(this_data_Field, NULL, "Area")
    this_data_Field@quant@units <- "1"
    
    # already aggregated to spatial map, so just save
    all_Map_Fields_list[[dataset_name]] <- this_data_Field
    
  }
  else {
    message("Biomass dataset not found, benchmark will be skipped.")
    do_Global_biomass <- FALSE
  }
  
  #### READ LPJ-GUESS BIOMASS DATA ####
  # loop through model runs to be processed
  for(this_sim_Source in all_simulation_Sources_list) {
    
    # check if file is present (if not don't include this run)
    this_benchmark_run_dir <- file.path(this_sim_Source@dir, this_benchmark$simulation)
    if(file.exists(file.path(this_benchmark_run_dir, paste0(this_benchmark$guess_var, ".out"))) || file.exists(file.path(this_benchmark_run_dir,  paste0(this_benchmark$guess_var, ".out.gz")))) {
      
      # read the full data and
      temp_simulation_Source <- this_sim_Source
      temp_simulation_Source@dir <- this_benchmark_run_dir
      suppressWarnings(
        all_Map_Fields_list[[this_sim_Source@id]] <- getField(source = temp_simulation_Source,
                                                              quant = this_benchmark$guess_var,
                                                              first.year = this_dataset$first_year,
                                                              last.year = this_dataset$last_year,
                                                              quick.read = quick_read,
                                                              quick.read.file = paste(this_benchmark$guess_var, version_label, sep = "_"),
                                                              layers = this_benchmark$guess_layers)
      )
      
      
      
      
      
      
      
      
    } # if file is present 
    else {
      message("Modelled biomass file not found, benchmark will be skipped.")
      do_Global_biomass <- FALSE
    }
    
  } # for each model run
  
  print(plotSpatial())
  
  
} # if do_Global_Biomass



```


<a href="#top">Back to top</a>

---


## Global Summary Table


TABLE FORMATTING: see here: [https://rmarkdown.rstudio.com/lesson-7.html](https://rmarkdown.rstudio.com/lesson-7.html)


``` {r Global summary, echo=FALSE, out.width = '100%', out.height= '150%'}


if(nrow(summary_table) > 0) {
  colnames(summary_table) <- summary_col_names
  kable(summary_table)
}


```

## Timing
Total run time:
``` {r time}

# report total run time
toc()

```